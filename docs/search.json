[
  {
    "objectID": "coursework.html",
    "href": "coursework.html",
    "title": "Coursework",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning in Python with Sci-Kit Learn\n\n\n\nPython\n\n\nML\n\n\nPandas\n\n\nSKLearn\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nGWAS and Personalities\n\n\n\nResearch\n\n\nGenetics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnergy and Pearson’s Distances as Metrics for Brain Region Activation Detection in Audiovisual fMRI Study\n\n\n\nSummer Institute in Biostatistics\n\n\nR\n\n\nResearch\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCO2 Levels in 20 Major Countries\n\n\n\nMachine Learning\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing Turbofan Jet Engines using Survival Analysis Methods\n\n\n\nSurvival Analysis\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAmerica Going Green: A Look at Renewable Energy Generation in the U.S.\n\n\n\nCorrelated Data\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "coursework/Machine Learning with Python and SciKit Learn/SciKit_Learn.html",
    "href": "coursework/Machine Learning with Python and SciKit Learn/SciKit_Learn.html",
    "title": "Machine Learning in Python with Sci-Kit Learn",
    "section": "",
    "text": "Online course through France Université Numérique. Coding in Python in Jupyter Notebooks while learning useful data science and data analysis packages like pandas, seaborn, and scikit-learn.\nGithub: https://github.com/tchuang1290/MLScikit-Learn/tree/main"
  },
  {
    "objectID": "projects/CO2/Final_Code_Appendix_Ayaa_Julia_Ting.html",
    "href": "projects/CO2/Final_Code_Appendix_Ayaa_Julia_Ting.html",
    "title": "Ayaa Asoba, Julia Coelho, Ting Huang stat253_project",
    "section": "",
    "text": "library(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(rpart.plot)\n\nLoading required package: rpart\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(tidyr)\nlibrary(ggpubr)\nlibrary(mgcv)\n\nLoading required package: nlme\n\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nThis is mgcv 1.9-0. For overview type 'help(\"mgcv-package\")'.\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tibble       3.2.1\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n✔ recipes      1.0.9     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ nlme::collapse()  masks dplyr::collapse()\n✖ purrr::discard()  masks scales::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ dials::prune()    masks rpart::prune()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(probably) #install.packages('probably')\n\n\nAttaching package: 'probably'\n\n\nThe following objects are masked from 'package:base':\n\n    as.factor, as.ordered\n\ntidymodels_prefer()\nesgdata &lt;- read_csv('ESGData.csv')\n\nNew names:\n• `` -&gt; `...67`\n\n\nRows: 16013 Columns: 67\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Country Name, Country Code, Indicator Name, Indicator Code\ndbl (62): 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, ...\nlgl  (1): ...67\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nesgdata %&gt;% distinct(`Indicator Name`,`Indicator Code`)\n\n# A tibble: 67 × 2\n   `Indicator Name`                                             `Indicator Code`\n   &lt;chr&gt;                                                        &lt;chr&gt;           \n 1 Access to clean fuels and technologies for cooking (% of po… EG.CFT.ACCS.ZS  \n 2 Access to electricity (% of population)                      EG.ELC.ACCS.ZS  \n 3 Adjusted savings: natural resources depletion (% of GNI)     NY.ADJ.DRES.GN.…\n 4 Adjusted savings: net forest depletion (% of GNI)            NY.ADJ.DFOR.GN.…\n 5 Agricultural land (% of land area)                           AG.LND.AGRI.ZS  \n 6 Agriculture, forestry, and fishing, value added (% of GDP)   NV.AGR.TOTL.ZS  \n 7 Annual freshwater withdrawals, total (% of internal resourc… ER.H2O.FWTL.ZS  \n 8 Annualized average growth rate in per capita real survey me… SI.SPR.PCAP.ZG  \n 9 Cause of death, by communicable diseases and maternal, pren… SH.DTH.COMM.ZS  \n10 Children in employment, total (% of children ages 7-14)      SL.TLF.0714.ZS  \n# ℹ 57 more rows"
  },
  {
    "objectID": "projects/CO2/Final_Code_Appendix_Ayaa_Julia_Ting.html#reading-in-data",
    "href": "projects/CO2/Final_Code_Appendix_Ayaa_Julia_Ting.html#reading-in-data",
    "title": "Ayaa Asoba, Julia Coelho, Ting Huang stat253_project",
    "section": "",
    "text": "library(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(rpart.plot)\n\nLoading required package: rpart\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(tidyr)\nlibrary(ggpubr)\nlibrary(mgcv)\n\nLoading required package: nlme\n\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nThis is mgcv 1.9-0. For overview type 'help(\"mgcv-package\")'.\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tibble       3.2.1\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n✔ recipes      1.0.9     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ nlme::collapse()  masks dplyr::collapse()\n✖ purrr::discard()  masks scales::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ dials::prune()    masks rpart::prune()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(probably) #install.packages('probably')\n\n\nAttaching package: 'probably'\n\n\nThe following objects are masked from 'package:base':\n\n    as.factor, as.ordered\n\ntidymodels_prefer()\nesgdata &lt;- read_csv('ESGData.csv')\n\nNew names:\n• `` -&gt; `...67`\n\n\nRows: 16013 Columns: 67\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Country Name, Country Code, Indicator Name, Indicator Code\ndbl (62): 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, ...\nlgl  (1): ...67\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nesgdata %&gt;% distinct(`Indicator Name`,`Indicator Code`)\n\n# A tibble: 67 × 2\n   `Indicator Name`                                             `Indicator Code`\n   &lt;chr&gt;                                                        &lt;chr&gt;           \n 1 Access to clean fuels and technologies for cooking (% of po… EG.CFT.ACCS.ZS  \n 2 Access to electricity (% of population)                      EG.ELC.ACCS.ZS  \n 3 Adjusted savings: natural resources depletion (% of GNI)     NY.ADJ.DRES.GN.…\n 4 Adjusted savings: net forest depletion (% of GNI)            NY.ADJ.DFOR.GN.…\n 5 Agricultural land (% of land area)                           AG.LND.AGRI.ZS  \n 6 Agriculture, forestry, and fishing, value added (% of GDP)   NV.AGR.TOTL.ZS  \n 7 Annual freshwater withdrawals, total (% of internal resourc… ER.H2O.FWTL.ZS  \n 8 Annualized average growth rate in per capita real survey me… SI.SPR.PCAP.ZG  \n 9 Cause of death, by communicable diseases and maternal, pren… SH.DTH.COMM.ZS  \n10 Children in employment, total (% of children ages 7-14)      SL.TLF.0714.ZS  \n# ℹ 57 more rows"
  },
  {
    "objectID": "projects/CO2/Final_Code_Appendix_Ayaa_Julia_Ting.html#data-cleaning",
    "href": "projects/CO2/Final_Code_Appendix_Ayaa_Julia_Ting.html#data-cleaning",
    "title": "Ayaa Asoba, Julia Coelho, Ting Huang stat253_project",
    "section": "Data cleaning",
    "text": "Data cleaning\n\n# data cleaning\nesgdata_clean &lt;- filter(esgdata,`Indicator Code`%in% c(\"EN.ATM.CO2E.PC\",\"EG.FEC.RNEW.ZS\", \"EG.ELC.RNEW.ZS\",\"EG.EGY.PRIM.PP.KD\",\"EG.USE.COMM.FO.ZS\",\"EN.POP.DNST\",\"AG.LND.AGRI.ZS\",\"NV.AGR.TOTL.ZS\",\"EG.ELC.ACCS.ZS\",\"SP.DYN.LE00.IN\",\"SI.DST.FRST.20\",\"SI.POV.GINI\",\"IT.NET.USER.ZS\",\"GE.EST\",\"AG.LND.FRST.ZS\",\"GB.XPD.RSDV.GD.ZS\",\"SE.PRM.ENRR\"))\nesgdata_clean &lt;- select(esgdata_clean,'Country Code','Country Name','Indicator Name','Indicator Code','1991','1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017','2018')\nesgdataAll &lt;- esgdata_clean %&gt;%\n  rename(CountryCode=\"Country Code\") %&gt;% rename(CountryName=\"Country Name\") %&gt;% rename(IndicatorName=\"Indicator Name\") %&gt;% rename(IndicatorCode=\"Indicator Code\")\nesgdataAll &lt;- esgdataAll %&gt;%\n  filter(!CountryCode %in% c(\"ARB\",\"CEB\",\"CSS\",\"ECA\",\"EAP\",\"EAR\",\"EAS\",\"ECS\",\"EMU\",\"EUU\",\"FCS\",\"HIC\",\"HPC\",\"IBD\",\"IBT\",\"IDA\",\"IDB\",\"IDX\",\"LDC\",\"LCN\",\"LIC\",\"LAC\",\"LMC\",\"LMY\",\"LTE\",\"MIC\",\"MEA\",\"MNA\",\"NAC\",\"OED\",\"OSS\",\"PRE\",\"PSS\",\"PST\",\"SAS\",\"SSA\",\"SSF\",\"SST\",\"TEA\",\"TMN\",\"TEC\",\"TLA\",\"TSA\",\"TSS\",\"UMC\",\"WLD\")) %&gt;%\n  pivot_longer(-c('CountryCode','CountryName','IndicatorName','IndicatorCode'), names_to = 'Year', values_to = 'Values') %&gt;% \n  select(-`IndicatorName`) %&gt;% \n  pivot_wider(names_from='IndicatorCode',values_from = 'Values')\nesgdataAll &lt;- esgdataAll %&gt;%\n   rename(electricity=\"EG.ELC.ACCS.ZS\") %&gt;% rename(agroLand=\"AG.LND.AGRI.ZS\") %&gt;% rename(agroValue=\"NV.AGR.TOTL.ZS\") %&gt;% rename(co2=\"EN.ATM.CO2E.PC\") %&gt;% rename(energyIntensity=\"EG.EGY.PRIM.PP.KD\") %&gt;% rename(forestArea=\"AG.LND.FRST.ZS\") %&gt;% rename(fossilFuel=\"EG.USE.COMM.FO.ZS\") %&gt;% rename(gini=\"SI.POV.GINI\") %&gt;% rename(govtEfficacy=\"GE.EST\") %&gt;% rename(incomeLowest20=\"SI.DST.FRST.20\") %&gt;% rename(internet=\"IT.NET.USER.ZS\") %&gt;% rename(lifeExpectancy=\"SP.DYN.LE00.IN\")  %&gt;% rename(popDensity=\"EN.POP.DNST\") %&gt;% rename(renewableElec=\"EG.ELC.RNEW.ZS\") %&gt;% rename(renewableEnergy=\"EG.FEC.RNEW.ZS\") %&gt;% rename(research=\"GB.XPD.RSDV.GD.ZS\") %&gt;% rename(schoolEnroll=\"SE.PRM.ENRR\")\nesgdataAll &lt;- esgdataAll %&gt;%\n  mutate(Year = as.numeric(Year))\nesgdataAll_sub &lt;- esgdataAll %&gt;% na.omit()\nesgdataAll_sub %&gt;% purrr::map (~sum(is.na(.)))\n\n$CountryCode\n[1] 0\n\n$CountryName\n[1] 0\n\n$Year\n[1] 0\n\n$electricity\n[1] 0\n\n$agroLand\n[1] 0\n\n$agroValue\n[1] 0\n\n$co2\n[1] 0\n\n$energyIntensity\n[1] 0\n\n$forestArea\n[1] 0\n\n$fossilFuel\n[1] 0\n\n$gini\n[1] 0\n\n$govtEfficacy\n[1] 0\n\n$incomeLowest20\n[1] 0\n\n$internet\n[1] 0\n\n$lifeExpectancy\n[1] 0\n\n$popDensity\n[1] 0\n\n$renewableElec\n[1] 0\n\n$renewableEnergy\n[1] 0\n\n$research\n[1] 0\n\n$schoolEnroll\n[1] 0\n\nesgdata_cv10 &lt;- vfold_cv(esgdataAll_sub, v = 10)  # 6 folds\ndata_rec &lt;- recipe(co2 ~ . , data = esgdataAll_sub) %&gt;%\n  update_role(`CountryCode`,new_role = 'ID') %&gt;%\n  update_role(`CountryName`,new_role = 'ID') %&gt;%\n    step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n    step_normalize(all_numeric_predictors()) %&gt;%  # important standardization step for LASSO\n    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables\ndata_rec %&gt;% prep(esgdataAll_sub) %&gt;%juice()\n\n# A tibble: 713 × 20\n   CountryCode CountryName    Year electricity agroLand agroValue\n   &lt;fct&gt;       &lt;fct&gt;         &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 ALB         Albania     -0.0415     0.291    -0.0194    1.94  \n 2 ARG         Argentina   -2.77      -0.304     0.170     0.0142\n 3 ARG         Argentina   -2.32      -0.238     0.173    -0.0472\n 4 ARG         Argentina   -1.86      -0.174     0.176    -0.145 \n 5 ARG         Argentina   -1.41      -0.112     0.180     0.802 \n 6 ARG         Argentina   -1.18      -0.0831    0.220     0.823 \n 7 ARG         Argentina   -0.952     -0.0548    0.285     0.486 \n 8 ARG         Argentina   -0.724     -0.0278    0.349     0.413 \n 9 ARG         Argentina   -0.497     -0.00166   0.410     0.241 \n10 ARG         Argentina   -0.269      0.0241    0.464     0.330 \n# ℹ 703 more rows\n# ℹ 14 more variables: energyIntensity &lt;dbl&gt;, forestArea &lt;dbl&gt;,\n#   fossilFuel &lt;dbl&gt;, gini &lt;dbl&gt;, govtEfficacy &lt;dbl&gt;, incomeLowest20 &lt;dbl&gt;,\n#   internet &lt;dbl&gt;, lifeExpectancy &lt;dbl&gt;, popDensity &lt;dbl&gt;,\n#   renewableElec &lt;dbl&gt;, renewableEnergy &lt;dbl&gt;, research &lt;dbl&gt;,\n#   schoolEnroll &lt;dbl&gt;, co2 &lt;dbl&gt;"
  },
  {
    "objectID": "projects/CO2/Final_Code_Appendix_Ayaa_Julia_Ting.html#regression-models",
    "href": "projects/CO2/Final_Code_Appendix_Ayaa_Julia_Ting.html#regression-models",
    "title": "Ayaa Asoba, Julia Coelho, Ting Huang stat253_project",
    "section": "Regression Models",
    "text": "Regression Models\n\nLinear Model Recipe\n\nesg_rec &lt;- recipe(co2 ~ . , data = esgdataAll_sub) %&gt;%\n  update_role(`Year`,new_role = 'ID') %&gt;%\n  update_role(`CountryCode`,new_role = 'ID') %&gt;%\n  update_role(`CountryName`,new_role = 'ID') %&gt;%\n    step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n    step_normalize(all_numeric_predictors()) %&gt;%  # important standardization step for LASSO\n    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables\n    \nesg_rec %&gt;% prep(esgdataAll_sub) %&gt;% juice()\n\n# A tibble: 713 × 20\n   CountryCode CountryName  Year electricity agroLand agroValue energyIntensity\n   &lt;fct&gt;       &lt;fct&gt;       &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;           &lt;dbl&gt;\n 1 ALB         Albania      2008     0.291    -0.0194    1.94            -0.640\n 2 ARG         Argentina    1996    -0.304     0.170     0.0142          -0.324\n 3 ARG         Argentina    1998    -0.238     0.173    -0.0472          -0.388\n 4 ARG         Argentina    2000    -0.174     0.176    -0.145           -0.298\n 5 ARG         Argentina    2002    -0.112     0.180     0.802           -0.186\n 6 ARG         Argentina    2003    -0.0831    0.220     0.823           -0.210\n 7 ARG         Argentina    2004    -0.0548    0.285     0.486           -0.207\n 8 ARG         Argentina    2005    -0.0278    0.349     0.413           -0.314\n 9 ARG         Argentina    2006    -0.00166   0.410     0.241           -0.306\n10 ARG         Argentina    2007     0.0241    0.464     0.330           -0.398\n# ℹ 703 more rows\n# ℹ 13 more variables: forestArea &lt;dbl&gt;, fossilFuel &lt;dbl&gt;, gini &lt;dbl&gt;,\n#   govtEfficacy &lt;dbl&gt;, incomeLowest20 &lt;dbl&gt;, internet &lt;dbl&gt;,\n#   lifeExpectancy &lt;dbl&gt;, popDensity &lt;dbl&gt;, renewableElec &lt;dbl&gt;,\n#   renewableEnergy &lt;dbl&gt;, research &lt;dbl&gt;, schoolEnroll &lt;dbl&gt;, co2 &lt;dbl&gt;\n\n\n\n\nLinear Model Fit\n\nlm_spec &lt;- \n    linear_reg() %&gt;% \n    set_engine(engine = 'lm') %&gt;% \n    set_mode('regression')\nesg_model_wf1 &lt;- workflow() %&gt;%\n  add_recipe(esg_rec) %&gt;% \n  add_model(lm_spec)\n \nesg_fit_model1 &lt;- esg_model_wf1 %&gt;% \n  fit(data = esgdataAll_sub)\nesg_fit_model1 %&gt;% tidy() \n\n# A tibble: 17 × 5\n   term            estimate std.error statistic   p.value\n   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)       6.55       0.105    62.3   4.59e-287\n 2 electricity       0.0221     0.170     0.130 8.97e-  1\n 3 agroLand         -0.143      0.146    -0.975 3.30e-  1\n 4 agroValue        -0.842      0.200    -4.21  2.86e-  5\n 5 energyIntensity   1.14       0.148     7.72  4.09e- 14\n 6 forestArea        0.264      0.161     1.64  1.00e-  1\n 7 fossilFuel        0.775      0.212     3.65  2.77e-  4\n 8 gini             -0.497      0.460    -1.08  2.81e-  1\n 9 govtEfficacy      2.18       0.251     8.69  2.52e- 17\n10 incomeLowest20   -0.408      0.433    -0.944 3.46e-  1\n11 internet          0.425      0.204     2.08  3.75e-  2\n12 lifeExpectancy   -0.835      0.240    -3.49  5.21e-  4\n13 popDensity       -0.492      0.123    -3.99  7.46e-  5\n14 renewableElec    -0.119      0.220    -0.541 5.89e-  1\n15 renewableEnergy  -1.20       0.306    -3.93  9.53e-  5\n16 research          0.477      0.187     2.55  1.10e-  2\n17 schoolEnroll     -0.185      0.134    -1.39  1.66e-  1\n\n\n\n# Getting metrics\ncv_output &lt;- fit_resamples( # new function for tuning parameters\n  esg_model_wf1, # workflow\n  resamples = esgdata_cv10, # cv folds\n  metrics = metric_set(rmse, mae, rsq)\n)\ncv_output %&gt;% collect_metrics()\n\n# A tibble: 3 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   1.99     10  0.0471 Preprocessor1_Model1\n2 rmse    standard   2.83     10  0.0983 Preprocessor1_Model1\n3 rsq     standard   0.608    10  0.0140 Preprocessor1_Model1\n\n# Residuals \nesg_fit_model1_residuals &lt;- bind_cols(esgdataAll_sub, esg_fit_model1 %&gt;% \n  predict(new_data = esgdataAll_sub)) %&gt;%\n  mutate(resid = co2 - .pred)\nggplot(esg_fit_model1_residuals, aes(x = .pred, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    ggtitle(\"Linear Regression Residuals\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()    # fit to the training data \n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nLASSO Model\n\ndata_rec &lt;- recipe(co2 ~ . , data = esgdataAll_sub) %&gt;%\n  update_role(`Year`,new_role = 'ID') %&gt;%\n  update_role(`CountryCode`,new_role = 'ID') %&gt;%\n  update_role(`CountryName`,new_role = 'ID') %&gt;%\n    step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n    step_normalize(all_numeric_predictors()) %&gt;%  # important standardization step for LASSO\n    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables\n# Lasso Model Spec with tune\nlm_lasso_spec_tune &lt;- \n  linear_reg() %&gt;%\n  set_args(mixture = 1, penalty = tune()) %&gt;% ## mixture = 1 indicates Lasso\n  set_engine(engine = 'glmnet') %&gt;% #note we are using a different engine\n  set_mode('regression') \n# Workflow (Recipe + Model)\nlasso_wf_tune &lt;- workflow() %&gt;% \n  add_recipe(data_rec) %&gt;%\n  add_model(lm_lasso_spec_tune) \n# Tune Model (trying a variety of values of Lambda penalty)\npenalty_grid &lt;- grid_regular(\n  penalty(range = c(-3, 1)), #log10 transformed \n  levels = 30)\ntune_output &lt;- tune_grid( # new function for tuning hyperparameters\n  lasso_wf_tune, # workflow\n  resamples = esgdata_cv10, # cv folds\n  metrics = metric_set(rmse, mae),\n  grid = penalty_grid # penalty grid defined above\n)\nautoplot(tune_output) + theme_classic()\n\n\n\n\n\n\n\n\n\nPicking LASSO Penalty\n\nbest_penalty &lt;- select_best(tune_output, metric = 'mae') # choose penalty value based on lowest mae\nbest_penalty\n\n# A tibble: 1 × 2\n  penalty .config              \n    &lt;dbl&gt; &lt;chr&gt;                \n1  0.0621 Preprocessor1_Model14\n\nbest_se_penalty &lt;- select_by_one_std_err(tune_output, metric = 'mae', desc(penalty)) # choose penalty value based on the largest penalty within 1 se of the lowest CV MAE\nbest_se_penalty\n\n# A tibble: 1 × 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt;  &lt;dbl&gt;\n1   0.221 mae     standard    2.00    10  0.0544 Preprocessor1_Mod…  1.97   2.01\n\nfinal_wf &lt;- finalize_workflow(lasso_wf_tune, best_penalty) # incorporates penalty value to workflow\nfinal_wf_se &lt;- finalize_workflow(lasso_wf_tune, best_se_penalty) # incorporates penalty value to workflow\nfinal_fit &lt;- fit(final_wf, data = esgdataAll_sub)\nfinal_fit_se &lt;- fit(final_wf_se, data = esgdataAll_sub)\ntidy(final_fit)\n\n# A tibble: 17 × 3\n   term            estimate penalty\n   &lt;chr&gt;              &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)       6.55    0.0621\n 2 electricity       0       0.0621\n 3 agroLand         -0.0705  0.0621\n 4 agroValue        -0.855   0.0621\n 5 energyIntensity   1.10    0.0621\n 6 forestArea        0.178   0.0621\n 7 fossilFuel        0.582   0.0621\n 8 gini             -0.0429  0.0621\n 9 govtEfficacy      1.89    0.0621\n10 incomeLowest20    0       0.0621\n11 internet          0.284   0.0621\n12 lifeExpectancy   -0.413   0.0621\n13 popDensity       -0.438   0.0621\n14 renewableElec    -0.199   0.0621\n15 renewableEnergy  -1.15    0.0621\n16 research          0.507   0.0621\n17 schoolEnroll     -0.219   0.0621\n\ntidy(final_fit_se)\n\n# A tibble: 17 × 3\n   term            estimate penalty\n   &lt;chr&gt;              &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)       6.55     0.221\n 2 electricity       0        0.221\n 3 agroLand          0        0.221\n 4 agroValue        -0.813    0.221\n 5 energyIntensity   0.896    0.221\n 6 forestArea        0        0.221\n 7 fossilFuel        0.159    0.221\n 8 gini              0        0.221\n 9 govtEfficacy      1.47     0.221\n10 incomeLowest20    0        0.221\n11 internet          0.0317   0.221\n12 lifeExpectancy    0        0.221\n13 popDensity       -0.242    0.221\n14 renewableElec    -0.262    0.221\n15 renewableEnergy  -1.13     0.221\n16 research          0.583    0.221\n17 schoolEnroll     -0.199    0.221\n\n\n\nglmnet_output &lt;- final_fit_se %&gt;% extract_fit_parsnip() %&gt;% pluck('fit') # way to get the original glmnet output\nlambdas &lt;- glmnet_output$lambda\ncoefs_lambdas &lt;- \n  coefficients(glmnet_output, s = lambdas )  %&gt;% \n  as.matrix() %&gt;%  \n  t() %&gt;% \n  as.data.frame() %&gt;% \n  mutate(lambda = lambdas ) %&gt;% \n  select(lambda, everything(), -`(Intercept)`) %&gt;% \n  pivot_longer(cols = -lambda, \n               names_to = \"term\", \n               values_to = \"coef\") %&gt;%\n  mutate(var = map_chr(stringr::str_split(term,\"_\"),~.[1]))\ncoefs_lambdas %&gt;%\n  ggplot(aes(x = lambda, y = coef, group = term, color = var)) +\n  geom_line() +\n  geom_vline(xintercept = best_se_penalty %&gt;% pull(penalty), linetype = 'dashed') + \n  theme_classic() + \n  theme(legend.position = \"bottom\", legend.text=element_text(size=8))\n\n\n\n\n\n\n\n# Create a boolean matrix (predictors x lambdas) of variable exclusion\nbool_predictor_exclude &lt;- glmnet_output$beta==0\n# Loop over each variable\nvar_imp &lt;- sapply(seq_len(nrow(bool_predictor_exclude)), function(row) {\n    this_coeff_path &lt;- bool_predictor_exclude[row,]\n    if(sum(this_coeff_path) == ncol(bool_predictor_exclude)){ return(0)}else{\n    return(ncol(bool_predictor_exclude) - which.min(this_coeff_path) + 1)}\n})\n# Create a dataset of this information and sort\nvar_imp_data &lt;- tibble(\n    var_name = rownames(bool_predictor_exclude),\n    var_imp = var_imp\n)\nvar_imp_data %&gt;% arrange(desc(var_imp))\n\n# A tibble: 16 × 2\n   var_name        var_imp\n   &lt;chr&gt;             &lt;dbl&gt;\n 1 govtEfficacy         75\n 2 agroValue            74\n 3 renewableElec        73\n 4 renewableEnergy      73\n 5 research             73\n 6 energyIntensity      63\n 7 gini                 63\n 8 schoolEnroll         60\n 9 popDensity           55\n10 fossilFuel           53\n11 internet             52\n12 forestArea           46\n13 agroLand             44\n14 lifeExpectancy       44\n15 incomeLowest20       18\n16 electricity          10\n\n\n\nfinal_fit_se %&gt;% tidy() %&gt;% filter(estimate != 0)\n\n# A tibble: 11 × 3\n   term            estimate penalty\n   &lt;chr&gt;              &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)       6.55     0.221\n 2 agroValue        -0.813    0.221\n 3 energyIntensity   0.896    0.221\n 4 fossilFuel        0.159    0.221\n 5 govtEfficacy      1.47     0.221\n 6 internet          0.0317   0.221\n 7 popDensity       -0.242    0.221\n 8 renewableElec    -0.262    0.221\n 9 renewableEnergy  -1.13     0.221\n10 research          0.583    0.221\n11 schoolEnroll     -0.199    0.221\n\ntune_output %&gt;% collect_metrics() %&gt;% filter(penalty == (best_se_penalty %&gt;% pull(penalty)))\n\n# A tibble: 2 × 7\n  penalty .metric .estimator  mean     n std_err .config              \n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1   0.221 mae     standard    2.00    10  0.0544 Preprocessor1_Model18\n2   0.221 rmse    standard    2.91    10  0.106  Preprocessor1_Model18\n\nlasso_mod_out &lt;- final_fit_se %&gt;%\n    predict(new_data = esgdataAll_sub) %&gt;%\n    bind_cols(esgdataAll_sub) %&gt;%\n    mutate(resid = co2 - .pred)\nggplot(esg_fit_model1_residuals, aes(x = .pred, y = resid)) +\n    geom_point() +\n    ggtitle('Linear Regression Final Model') +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()    # fit to the training data \n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\nlasso_mod_out %&gt;% \n  ggplot(aes(x = .pred, y = resid)) + \n  ggtitle('LASSO Residuals') +\n  geom_point() +\n  geom_smooth(se = FALSE) + \n  geom_hline(yintercept = 0, color = \"red\") + \n  theme_classic()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nGAMs\n\ngam_spec &lt;- \n  gen_additive_mod() %&gt;%\n  set_engine(engine = 'mgcv') %&gt;%\n  set_mode('regression') \ngam_mod &lt;- fit(gam_spec,\n    co2 ~ s(agroValue) + s(energyIntensity) + s(fossilFuel) + s(govtEfficacy) + s(popDensity) + s(renewableElec) + s(research) + s(schoolEnroll),\n    data = esgdataAll_sub\n)\n\n\ngam_mod %&gt;% pluck('fit') %&gt;% plot( all.terms = TRUE, pages = 1)\n\n\n\n\n\n\n\ngam_mod %&gt;% pluck('fit') %&gt;% summary() \n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nco2 ~ s(agroValue) + s(energyIntensity) + s(fossilFuel) + s(govtEfficacy) + \n    s(popDensity) + s(renewableElec) + s(research) + s(schoolEnroll)\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.55010    0.06926   94.58   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                     edf Ref.df      F  p-value    \ns(agroValue)       8.600  8.948 13.878  &lt; 2e-16 ***\ns(energyIntensity) 8.801  8.985 27.180  &lt; 2e-16 ***\ns(fossilFuel)      8.468  8.909 11.883  &lt; 2e-16 ***\ns(govtEfficacy)    7.026  8.134  9.503  &lt; 2e-16 ***\ns(popDensity)      8.957  8.999 13.224  &lt; 2e-16 ***\ns(renewableElec)   7.970  8.705  5.465 1.28e-06 ***\ns(research)        8.182  8.817  9.380  &lt; 2e-16 ***\ns(schoolEnroll)    7.599  8.511  5.386 1.24e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.831   Deviance explained = 84.6%\nGCV = 3.7724  Scale est. = 3.42      n = 713\n\n\n\ngam_data_rec &lt;- recipe(co2 ~ agroValue + energyIntensity + fossilFuel + govtEfficacy + popDensity + renewableElec + research + schoolEnroll , data = esgdataAll_sub) %&gt;%\n    step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n    step_dummy(all_nominal_predictors()) %&gt;%  # creates indicator variables for categorical variables\n     step_ns(agroValue, deg_free = 9) %&gt;% \n     step_ns(energyIntensity, deg_free = 9) %&gt;%\n     step_ns(fossilFuel, deg_free = 8) %&gt;%\n     step_ns(govtEfficacy, deg_free = 7) %&gt;%\n     step_ns(popDensity, deg_free = 9) %&gt;%\n     step_ns(renewableElec, deg_free = 8) %&gt;%\n     step_ns(research, deg_free = 8) %&gt;% \n    step_ns(schoolEnroll, deg_free = 8)\nspline_wf &lt;- workflow() %&gt;%\n    add_model(lm_spec) %&gt;%\n    add_recipe(gam_data_rec)\nfit_resamples(\n    spline_wf ,\n    resamples = esgdata_cv10, # cv folds\n    metrics = metric_set(mae,rsq)                     \n) %&gt;% collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   1.37     10  0.0404 Preprocessor1_Model1\n2 rsq     standard   0.831    10  0.0130 Preprocessor1_Model1\n\nesg_gam_model2 &lt;- spline_wf %&gt;% fit(data=esgdataAll_sub)\nesg_gam_model2_residuals &lt;- bind_cols(esgdataAll_sub, esg_gam_model2 %&gt;% \n  predict(new_data = esgdataAll_sub)) %&gt;%\n  mutate(resid = co2 - .pred)\nresid_agro &lt;- ggplot(esg_gam_model2_residuals, aes(x = agroValue, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()   \nresid_energy &lt;- ggplot(esg_gam_model2_residuals, aes(x = energyIntensity, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic() \nresid_fossil &lt;- ggplot(esg_gam_model2_residuals, aes(x = fossilFuel, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()\nresid_govt &lt;- ggplot(esg_gam_model2_residuals, aes(x = govtEfficacy, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()\nresid_density &lt;- ggplot(esg_gam_model2_residuals, aes(x = popDensity, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()\nresid_renewable &lt;- ggplot(esg_gam_model2_residuals, aes(x = renewableElec, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()\nresid_research &lt;- ggplot(esg_gam_model2_residuals, aes(x = research, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()\nresid_school &lt;- ggplot(esg_gam_model2_residuals, aes(x = agroValue , y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()\nggplot(esg_gam_model2_residuals, aes(x = resid, y = co2)) +\n    geom_point(alpha = 0.25) +\n    geom_smooth(color = \"blue\", se = FALSE) +\n    theme_classic()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggarrange(resid_agro, resid_energy, resid_fossil, resid_govt, resid_density, resid_renewable, resid_research, resid_school + rremove(\"x.text\"), \n          labels = c(\"agroValue Residuals\", \"energyIntensity Residuals\", \"fossilFuel Residuals\", \"govtEfficacy Residuals\", \"popDensity Residuals\", \"renewableElec Residuals\", \"research Residuals\", \"schoolEnroll Residuals\"),\n          ncol = 4, nrow = 2)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "projects/CO2/Final_Code_Appendix_Ayaa_Julia_Ting.html#classification-models",
    "href": "projects/CO2/Final_Code_Appendix_Ayaa_Julia_Ting.html#classification-models",
    "title": "Ayaa Asoba, Julia Coelho, Ting Huang stat253_project",
    "section": "Classification Models",
    "text": "Classification Models\n\nmean(esgdataAll_sub[[\"co2\"]])\n\n[1] 6.550097\n\nesgdataAll_sub &lt;- esgdataAll_sub %&gt;%\n  mutate(CO2cat = if_else(esgdataAll_sub$co2 &gt; 6.550097, 'high_co2','low_co2'))\nesgdataAll_sub &lt;- esgdataAll_sub %&gt;%\n  mutate(CO2cat = relevel(factor(CO2cat), ref= 'low_co2'))\n\n\nWe will be using 6.550097 as the split for deciding if the country has high CO2 emissions or low CO2 emissions. ### Logistic Regression\n\n\n# Logistic Regression Model Spec\n\nlogistic_spec &lt;- logistic_reg() %&gt;%\n    set_engine('glm') %&gt;%\n    set_mode('classification')\n    \n# Recipe\n logistic_rec &lt;- recipe( CO2cat ~ ., data = esgdataAll_sub) %&gt;%\n    update_role(`CountryCode`,new_role = 'ID') %&gt;%\n     update_role(`CountryName`,new_role = 'ID') %&gt;%\n     step_rm(co2) %&gt;%\n     step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n     step_normalize(all_numeric_predictors()) %&gt;%  # important standardization step for LASSO\n     step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables\n# Workflow (Recipe + Model)\n\nlog_wf &lt;- workflow() %&gt;% \n    add_recipe(logistic_rec) %&gt;%\n    add_model(logistic_spec) \n# Fit Model to Training Data\nlog_fit &lt;- fit(log_wf, data = esgdataAll_sub)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\nExamining the logistic model\n\n# Print out Coefficients\nlog_fit %&gt;% tidy()\n\n# A tibble: 18 × 5\n   term            estimate std.error statistic  p.value\n   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)       -2.16      0.351    -6.16  7.38e-10\n 2 Year              -0.770     0.276    -2.79  5.32e- 3\n 3 electricity        0.517     1.09      0.476 6.34e- 1\n 4 agroLand          -0.654     0.260    -2.51  1.21e- 2\n 5 agroValue         -3.62      0.566    -6.38  1.72e-10\n 6 energyIntensity    1.77      0.287     6.17  6.68e-10\n 7 forestArea        -0.234     0.239    -0.979 3.27e- 1\n 8 fossilFuel         2.04      0.288     7.09  1.30e-12\n 9 gini              -0.431     0.744    -0.580 5.62e- 1\n10 govtEfficacy       0.954     0.416     2.29  2.19e- 2\n11 incomeLowest20    -0.484     0.640    -0.757 4.49e- 1\n12 internet           1.23      0.437     2.82  4.84e- 3\n13 lifeExpectancy    -0.357     0.286    -1.25  2.12e- 1\n14 popDensity        -0.794     0.164    -4.85  1.25e- 6\n15 renewableElec     -0.624     0.404    -1.54  1.23e- 1\n16 renewableEnergy   -0.392     0.511    -0.767 4.43e- 1\n17 research           0.531     0.267     1.99  4.70e- 2\n18 schoolEnroll      -0.616     0.223    -2.75  5.88e- 3\n\n# Get Exponentiated coefficients + CI\nlog_fit %&gt;% tidy() %&gt;%\n  mutate(OR.conf.low = exp(estimate - 1.96*std.error), OR.conf.high = exp(estimate + 1.96*std.error)) %&gt;% # do this first\n  mutate(OR = exp(estimate))\n\n# A tibble: 18 × 8\n   term    estimate std.error statistic  p.value OR.conf.low OR.conf.high     OR\n   &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n 1 (Inter…   -2.16      0.351    -6.16  7.38e-10     0.0578        0.229  0.115 \n 2 Year      -0.770     0.276    -2.79  5.32e- 3     0.269         0.796  0.463 \n 3 electr…    0.517     1.09      0.476 6.34e- 1     0.200        14.1    1.68  \n 4 agroLa…   -0.654     0.260    -2.51  1.21e- 2     0.312         0.866  0.520 \n 5 agroVa…   -3.62      0.566    -6.38  1.72e-10     0.00886       0.0816 0.0269\n 6 energy…    1.77      0.287     6.17  6.68e-10     3.36         10.4    5.90  \n 7 forest…   -0.234     0.239    -0.979 3.27e- 1     0.495         1.26   0.791 \n 8 fossil…    2.04      0.288     7.09  1.30e-12     4.39         13.6    7.71  \n 9 gini      -0.431     0.744    -0.580 5.62e- 1     0.151         2.79   0.650 \n10 govtEf…    0.954     0.416     2.29  2.19e- 2     1.15          5.87   2.60  \n11 income…   -0.484     0.640    -0.757 4.49e- 1     0.176         2.16   0.616 \n12 intern…    1.23      0.437     2.82  4.84e- 3     1.45          8.05   3.42  \n13 lifeEx…   -0.357     0.286    -1.25  2.12e- 1     0.400         1.23   0.700 \n14 popDen…   -0.794     0.164    -4.85  1.25e- 6     0.328         0.623  0.452 \n15 renewa…   -0.624     0.404    -1.54  1.23e- 1     0.243         1.18   0.536 \n16 renewa…   -0.392     0.511    -0.767 4.43e- 1     0.248         1.84   0.676 \n17 resear…    0.531     0.267     1.99  4.70e- 2     1.01          2.87   1.70  \n18 school…   -0.616     0.223    -2.75  5.88e- 3     0.349         0.837  0.540 \n\n\n\nlogistic_output &lt;-  esgdataAll_sub %&gt;%\n  bind_cols(predict(log_fit, new_data = esgdataAll_sub, type = 'prob')) \n# Hard predictions (you pick threshold)\nlogistic_output &lt;- logistic_output %&gt;%\n  mutate(.pred_class = make_two_class_pred(.pred_low_co2, levels(CO2cat), threshold = .55)) #Try changing threshold (.5, 0, 1, .2, .8)\n# Visualize Soft Predictions\nlogistic_output %&gt;%\n  ggplot(aes(x = CO2cat, y = .pred_low_co2)) +\n  geom_boxplot() + \n  geom_hline(yintercept = 0.55, color='red') +  # try changing threshold\n  labs(y = 'Predicted Probability of Low CO2', x = 'Observed Outcome') +\n  theme_classic()\n\n\n\n\n\n\n\nlogistic_output %&gt;%\n  conf_mat(truth = CO2cat, estimate = .pred_class)\n\n          Truth\nPrediction low_co2 high_co2\n  low_co2      357       39\n  high_co2      45      272\n\nlog_metrics &lt;- metric_set(sens, yardstick::spec, accuracy) # these metrics are based on hard predictions\n#sens: sensitivity = chance of correctly predicting second level, given second level (Yes)\n#spec: specificity = chance of correctly predicting first level, given first level (No)\n#accuracy: accuracy = chance of correctly predicting outcome\nlogistic_output %&gt;% \n   log_metrics(estimate = .pred_class, truth = CO2cat, event_level = \"second\") # set second level of outcome as \"success\"\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 sens     binary         0.875\n2 spec     binary         0.888\n3 accuracy binary         0.882\n\n\n\n logistic_output &lt;-  esgdataAll_sub %&gt;%\n   bind_cols(predict(log_fit, new_data = esgdataAll_sub, type = 'prob')) \n logistic_roc &lt;- logistic_output %&gt;% \n     roc_curve(CO2cat, .pred_high_co2, event_level = \"second\") # set second level of outcome as \"success\"\n autoplot(logistic_roc) + theme_classic()\n\n\n\n\n\n\n\n set.seed(123)\n esgdataAll_sub_cv10 &lt;- vfold_cv(esgdataAll_sub, v = 10)\n # CV Fit Model\n log_cv_fit &lt;- fit_resamples(\n     log_wf, \n     resamples = esgdataAll_sub_cv10,\n     metrics = metric_set(sens, yardstick::spec, accuracy, roc_auc),\n     control = control_resamples(save_pred = TRUE, event_level = 'second'))  # you need predictions for ROC calculations\n\n→ A | warning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x10\n\n\n\n\n collect_metrics(log_cv_fit) #default threshold is 0.5\n\n# A tibble: 4 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.864    10 0.0128  Preprocessor1_Model1\n2 roc_auc  binary     0.943    10 0.00729 Preprocessor1_Model1\n3 sens     binary     0.843    10 0.0250  Preprocessor1_Model1\n4 spec     binary     0.882    10 0.0139  Preprocessor1_Model1\n\n\n\nDecision tree\n\nset.seed(726) # don't change this\nct_spec_tune &lt;- decision_tree() %&gt;%\n  set_engine(engine = 'rpart') %&gt;%\n  set_args(cost_complexity = tune(),  \n           min_n = 2, \n           tree_depth = NULL) %&gt;% \n  set_mode('classification') \ndata_rec &lt;- recipe(CO2cat ~ ., data = esgdataAll_sub) %&gt;%\n    update_role(`CountryCode`,new_role = 'ID') %&gt;%\n    update_role(`CountryName`,new_role = 'ID') %&gt;%\n    step_rm(co2) %&gt;%\n    step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables\ndata_wf_tune &lt;- workflow() %&gt;%\n  add_model(ct_spec_tune) %&gt;%\n  add_recipe(data_rec)\nparam_grid &lt;- grid_regular(cost_complexity(range = c(-5, 1)), levels = 10) \ntune_res &lt;- tune_grid(\n  data_wf_tune, \n  resamples = esgdataAll_sub_cv10, \n  grid = param_grid, \n  metrics = metric_set(accuracy) #change this for regression trees\n)\n\n\nautoplot(tune_res) + theme_classic()\n\n\n\n\n\n\n\n\n\nbest_complexity &lt;- select_by_one_std_err(tune_res, metric = 'accuracy', desc(cost_complexity))\ndata_wf_final &lt;- finalize_workflow(data_wf_tune, best_complexity)\nesg_final_fit &lt;- fit(data_wf_final, data = esgdataAll_sub)\n\n\nesg_final_fit %&gt;% extract_fit_engine() %&gt;% rpart.plot()\n\nWarning: Cannot retrieve the data used to build the model (so cannot determine roundint and is.binary for the variables).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE.\n\n\n\n\n\n\n\n\n\n\ntree_mod_highcp &lt;- fit(\n    data_wf_tune %&gt;%\n        update_model(ct_spec_tune %&gt;% set_args(cost_complexity = .01)),\n    data = esgdataAll_sub\n)\ntree_mod_highcp %&gt;% extract_fit_engine() %&gt;% rpart.plot()\n\nWarning: Cannot retrieve the data used to build the model (so cannot determine roundint and is.binary for the variables).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE.\n\n\n\n\n\n\n\n\n\n\n\nRandom Forest\n\n# Model Specification\nrf_spec &lt;- rand_forest() %&gt;%\n  set_engine(engine = 'ranger') %&gt;% \n  set_args(mtry = NULL, # size of random subset of variables; default is floor(sqrt(number of total predictors))\n           trees = 1000, # Number of trees\n           min_n = 2,\n           probability = FALSE, # FALSE: get hard predictions (not needed for regression)\n           importance = 'impurity') %&gt;% # we'll come back to this at the end\n  set_mode('classification') # change this for regression\n# Recipe\ndata_rec_rf &lt;- recipe(CO2cat ~ ., data = esgdataAll_sub) %&gt;%\n  update_role(`CountryCode`,new_role = 'ID') %&gt;%\n    update_role(`CountryName`,new_role = 'ID') %&gt;%\n    step_rm(co2) %&gt;%\n    step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables\n# Workflows\ndata_wf_mtry2 &lt;- workflow() %&gt;%\n  add_model(rf_spec %&gt;% set_args(mtry = 2)) %&gt;%\n  add_recipe(data_rec_rf)\n## Create workflows for mtry = 4, 9, and 17\ndata_wf_mtry4 &lt;- workflow() %&gt;%\n  add_model(rf_spec %&gt;% set_args(mtry = 4)) %&gt;%\n  add_recipe(data_rec_rf)\ndata_wf_mtry9 &lt;- workflow() %&gt;%\n  add_model(rf_spec %&gt;% set_args(mtry = 9)) %&gt;%\n  add_recipe(data_rec_rf)\ndata_wf_mtry17 &lt;- workflow() %&gt;%\n  add_model(rf_spec %&gt;% set_args(mtry = 17)) %&gt;%\n  add_recipe(data_rec_rf)\n\n\nset.seed(726) # make sure to run this before each fit so that you have the same 1000 trees\ndata_fit_mtry2 &lt;- fit(data_wf_mtry2, data = esgdataAll_sub)\nset.seed(726)\ndata_fit_mtry4 &lt;- fit(data_wf_mtry4, data = esgdataAll_sub)\nset.seed(726) \ndata_fit_mtry9 &lt;- fit(data_wf_mtry9, data = esgdataAll_sub)\nset.seed(726)\ndata_fit_mtry17 &lt;- fit(data_wf_mtry17, data = esgdataAll_sub)\n\n\nrf_OOB_output &lt;- function(fit_model, model_label, truth){\n    tibble(\n          .pred_class = fit_model %&gt;% extract_fit_engine() %&gt;% pluck('predictions'), #OOB predictions\n          class = truth,\n          model = model_label\n      )\n}\n#check out the function output\nrf_OOB_output(data_fit_mtry2,'mtry2', esgdataAll_sub %&gt;% pull(CO2cat))\n\n# A tibble: 713 × 3\n   .pred_class class   model\n   &lt;fct&gt;       &lt;fct&gt;   &lt;chr&gt;\n 1 low_co2     low_co2 mtry2\n 2 low_co2     low_co2 mtry2\n 3 low_co2     low_co2 mtry2\n 4 low_co2     low_co2 mtry2\n 5 low_co2     low_co2 mtry2\n 6 low_co2     low_co2 mtry2\n 7 low_co2     low_co2 mtry2\n 8 low_co2     low_co2 mtry2\n 9 low_co2     low_co2 mtry2\n10 low_co2     low_co2 mtry2\n# ℹ 703 more rows\n\n\n\ndata_rf_OOB_output &lt;- bind_rows(\n    rf_OOB_output(data_fit_mtry2,'mtry2', esgdataAll_sub %&gt;% pull(CO2cat)),\n    rf_OOB_output(data_fit_mtry4,'mtry4', esgdataAll_sub %&gt;% pull(CO2cat)),\n    rf_OOB_output(data_fit_mtry9,'mtry9', esgdataAll_sub %&gt;% pull(CO2cat)),\n    rf_OOB_output(data_fit_mtry17,'mtry17', esgdataAll_sub %&gt;% pull(CO2cat))\n)\ndata_rf_OOB_output %&gt;% \n    group_by(model) %&gt;%\n    accuracy(truth = class, estimate = .pred_class)\n\n# A tibble: 4 × 4\n  model  .metric  .estimator .estimate\n  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 mtry17 accuracy binary         0.954\n2 mtry2  accuracy binary         0.959\n3 mtry4  accuracy binary         0.959\n4 mtry9  accuracy binary         0.962\n\n\n\ndata_rf_OOB_output %&gt;% \n    group_by(model) %&gt;%\n    accuracy(truth = class, estimate = .pred_class) %&gt;%\n  mutate(mtry = as.numeric(stringr::str_replace(model,'mtry',''))) %&gt;%\n  ggplot(aes(x = mtry, y = .estimate )) + \n  geom_point() +\n  geom_line() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nrf_OOB_output(data_fit_mtry9,'mtry9', esgdataAll_sub %&gt;% pull(CO2cat)) %&gt;%\n    conf_mat(truth = class, estimate= .pred_class)\n\n          Truth\nPrediction low_co2 high_co2\n  low_co2      389       14\n  high_co2      13      297\n\n\n\ndata_fit_mtry9 %&gt;% \n    extract_fit_engine() %&gt;% \n    vip(num_features = 30) + theme_classic() #based on impurity"
  },
  {
    "objectID": "projects/CO2/Final_Code_Appendix_Ayaa_Julia_Ting.html#clustering",
    "href": "projects/CO2/Final_Code_Appendix_Ayaa_Julia_Ting.html#clustering",
    "title": "Ayaa Asoba, Julia Coelho, Ting Huang stat253_project",
    "section": "Clustering",
    "text": "Clustering\n\nSUB = esgdataAll_sub %&gt;%\n  select(co2,govtEfficacy,agroValue,research,renewableEnergy)\nset.seed(123)\nkclust_k4 &lt;- kmeans(scale(SUB), centers = 4)\nesgdataAll_sub &lt;- esgdataAll_sub %&gt;%\n    mutate(kclust_4 = factor(kclust_k4$cluster))\nggplot(esgdataAll_sub,aes(co2,govtEfficacy,color=kclust_4)) +\n  geom_point()\n\n\n\n\n\n\n\nggplot(esgdataAll_sub,aes(co2,agroValue,color=kclust_4)) +\n  geom_point()\n\n\n\n\n\n\n\nggplot(esgdataAll_sub,aes(co2,renewableEnergy,color=kclust_4)) +\n  geom_point()\n\n\n\n\n\n\n\nggplot(esgdataAll_sub,aes(co2,research,color=kclust_4)) +\n  geom_point()\n\n\n\n\n\n\n\nesgdataAll_sub %&gt;%\n    group_by(kclust_4) %&gt;%\n    summarize(across(c(co2,govtEfficacy,agroValue,research,renewableEnergy), mean))\n\n# A tibble: 4 × 6\n  kclust_4   co2 govtEfficacy agroValue research renewableEnergy\n  &lt;fct&gt;    &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;\n1 1        10.5         1.71       1.64    2.46             22.4\n2 2         1.03       -0.689     20.3     0.193            51.3\n3 3         3.42       -0.107      7.82    0.441            20.6\n4 4         7.85        0.823      2.82    1.01             10.3\n\nesgdataAll_sub %&gt;%\n  count(kclust_4, CountryName)\n\n# A tibble: 102 × 3\n   kclust_4 CountryName        n\n   &lt;fct&gt;    &lt;chr&gt;          &lt;int&gt;\n 1 1        Australia          2\n 2 1        Austria           14\n 3 1        Belgium           14\n 4 1        Canada             9\n 5 1        Czech Republic     2\n 6 1        Denmark           12\n 7 1        Estonia            6\n 8 1        Finland           14\n 9 1        France            13\n10 1        Germany           16\n# ℹ 92 more rows\n\n\n\nesg_cluster_ss &lt;- function(k){\n    # Perform clustering\n    kclust &lt;- kmeans(scale(SUB), centers = k)\n    # Return the total within-cluster sum of squares\n    return(kclust$tot.withinss)\n}\ntibble(\n    k = 1:15,\n    tot_wc_ss = purrr::map_dbl(1:15, esg_cluster_ss)\n) %&gt;% \n    ggplot(aes(x = k, y = tot_wc_ss)) +\n    geom_point() + \n    labs(x = \"Number of clusters\",y = 'Total within-cluster sum of squares') + \n    theme_classic()"
  },
  {
    "objectID": "projects/Survival/Survival_Analysis.html",
    "href": "projects/Survival/Survival_Analysis.html",
    "title": "Analyzing Turbofan Jet Engines using Survival Analysis Methods",
    "section": "",
    "text": "Using Kaplan Meier curves and a Cox proportional hazard model, I analyzed the reliability of simulated turbo fan jet engines from data produced by Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) developed by NASA. This paper and presentation was produced as part of the class STAT 453 “Survival Analysis” at Macalester College.\nProducts\nPaper: https://docs.google.com/document/d/1yq_Jd_1LwriNe1Cd6GYp1IDszdTUs1tMx1HhQSqNwN0/edit\nPresentation: https://docs.google.com/presentation/d/1SZj3brdOlm7r6wHzMqbohh-ljHUzDvJ4sE0llfH7NKY/edit#slide=id.p"
  },
  {
    "objectID": "projects/BOLD/BOLD.html",
    "href": "projects/BOLD/BOLD.html",
    "title": "Energy and Pearson’s Distances as Metrics for Brain Region Activation Detection in Audiovisual fMRI Study",
    "section": "",
    "text": "This presentation was completed as part of the Summer Institute in Biostatistics at the University of Iowa and completed with Megan Gelement who was, at the time, a graduate student at Tufts University seeking her master’s degree in computer science.\nThe goal of this research was to determine measures of statistical distance that could be used to detect brain region activation. Since the brain is always active in some capacity, determining if a brain region is reacting to certain stimuli can be difficult.\nProducts:\nPresentation: https://docs.google.com/presentation/d/1kmFVMXeNdWhC2QxnQHdPnNxQeJv75aSqsETd-ZFTruk/edit?usp=sharing"
  },
  {
    "objectID": "projects/Personality/Personality.html",
    "href": "projects/Personality/Personality.html",
    "title": "GWAS and Personalities",
    "section": "",
    "text": "Produced for STAT 494 “Statistical Genetics” at Macalester College with Lucy Tran ’23.\nProducts\nPresentation: https://docs.google.com/presentation/d/1Ti9fU15B1p2mDweW9JadluguxhnSI7qk8W8jGvB5DH4/edit?usp=sharing"
  },
  {
    "objectID": "projects/Renewable Energy/Renewable_Energy.html",
    "href": "projects/Renewable Energy/Renewable_Energy.html",
    "title": "America Going Green: A Look at Renewable Energy Generation in the U.S.",
    "section": "",
    "text": "Results produced as part of the class STAT 452 “Correlated Data” at Macalester College with Jack Acomb and Claire Wilson. Presentation produced separately as my senior capstone presentation.\nProducts\nPresentation: https://docs.google.com/presentation/d/1zKiCGBQ21L8hAcr4kaQXNjakufoih9xJnlrk9HtvWEQ/edit?usp=sharing"
  },
  {
    "objectID": "projects/CO2/CO2.html",
    "href": "projects/CO2/CO2.html",
    "title": "CO2 Levels in 20 Major Countries",
    "section": "",
    "text": "Completed as final project for STAT 253 “Statistical Machine Learning” at Macalester College with Ayaa Asoba and Julia Coelho\nPresentation: https://docs.google.com/presentation/d/1cRzZPT1LijIIKyGGKAEzkKDYWMsYUf22/edit?usp=sharing&ouid=116188639352950574208&rtpof=true&sd=true\nGithub: https://github.com/tchuang1290/StatMLFinalProj\nRMD: Final Code Appendix"
  },
  {
    "objectID": "other/piano_recital/recital.html",
    "href": "other/piano_recital/recital.html",
    "title": "Senior Capstone-Piano Recital",
    "section": "",
    "text": "50 minute recital performed as my capstone project for my music major.\nProgram:\nEtude No 16 - Philip Glass\nPrelude and Fugue No 10 - Dmitri Shostakovich\nSonata - Ludwig Van Beethoven\nPiece - Paul Gabriel Cosme\nBallade No 4 - Frederic Chopin\nWatch it here: https://vimeo.com/822164806/b3802f7e42"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ting-Chien Huang",
    "section": "",
    "text": "Pronunciation  he/him/his\n\n\nMS in Statistics  Sept 2023 - Present | University of Minnesota\nBA in Statistics and Music  2023 | Macalester College"
  },
  {
    "objectID": "index.html#ting-chien-huang",
    "href": "index.html#ting-chien-huang",
    "title": "Ting-Chien Huang",
    "section": "",
    "text": "Pronunciation  he/him/his\n\n\nMS in Statistics  Sept 2023 - Present | University of Minnesota\nBA in Statistics and Music  2023 | Macalester College"
  },
  {
    "objectID": "other.html",
    "href": "other.html",
    "title": "Other",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nSenior Capstone-Piano Recital\n\n\n\nMusic\n\n\nPiano\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Rmd/Final_Code_Appendix_Ayaa_Julia_Ting.html",
    "href": "Rmd/Final_Code_Appendix_Ayaa_Julia_Ting.html",
    "title": "Ayaa Asoba, Julia Coelho, Ting Huang stat253_project",
    "section": "",
    "text": "library(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(rpart.plot)\n\nLoading required package: rpart\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(tidyr)\nlibrary(ggpubr)\nlibrary(mgcv)\n\nLoading required package: nlme\n\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nThis is mgcv 1.9-0. For overview type 'help(\"mgcv-package\")'.\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tibble       3.2.1\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n✔ recipes      1.0.9     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ nlme::collapse()  masks dplyr::collapse()\n✖ purrr::discard()  masks scales::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ dials::prune()    masks rpart::prune()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(probably) #install.packages('probably')\n\n\nAttaching package: 'probably'\n\n\nThe following objects are masked from 'package:base':\n\n    as.factor, as.ordered\n\ntidymodels_prefer()\nesgdata &lt;- read_csv('ESGData.csv')\n\nNew names:\n• `` -&gt; `...67`\n\n\nRows: 16013 Columns: 67\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Country Name, Country Code, Indicator Name, Indicator Code\ndbl (62): 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, ...\nlgl  (1): ...67\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nesgdata %&gt;% distinct(`Indicator Name`,`Indicator Code`)\n\n# A tibble: 67 × 2\n   `Indicator Name`                                             `Indicator Code`\n   &lt;chr&gt;                                                        &lt;chr&gt;           \n 1 Access to clean fuels and technologies for cooking (% of po… EG.CFT.ACCS.ZS  \n 2 Access to electricity (% of population)                      EG.ELC.ACCS.ZS  \n 3 Adjusted savings: natural resources depletion (% of GNI)     NY.ADJ.DRES.GN.…\n 4 Adjusted savings: net forest depletion (% of GNI)            NY.ADJ.DFOR.GN.…\n 5 Agricultural land (% of land area)                           AG.LND.AGRI.ZS  \n 6 Agriculture, forestry, and fishing, value added (% of GDP)   NV.AGR.TOTL.ZS  \n 7 Annual freshwater withdrawals, total (% of internal resourc… ER.H2O.FWTL.ZS  \n 8 Annualized average growth rate in per capita real survey me… SI.SPR.PCAP.ZG  \n 9 Cause of death, by communicable diseases and maternal, pren… SH.DTH.COMM.ZS  \n10 Children in employment, total (% of children ages 7-14)      SL.TLF.0714.ZS  \n# ℹ 57 more rows"
  },
  {
    "objectID": "Rmd/Final_Code_Appendix_Ayaa_Julia_Ting.html#reading-in-data",
    "href": "Rmd/Final_Code_Appendix_Ayaa_Julia_Ting.html#reading-in-data",
    "title": "Ayaa Asoba, Julia Coelho, Ting Huang stat253_project",
    "section": "",
    "text": "library(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(rpart.plot)\n\nLoading required package: rpart\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(tidyr)\nlibrary(ggpubr)\nlibrary(mgcv)\n\nLoading required package: nlme\n\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nThis is mgcv 1.9-0. For overview type 'help(\"mgcv-package\")'.\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tibble       3.2.1\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n✔ recipes      1.0.9     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ nlme::collapse()  masks dplyr::collapse()\n✖ purrr::discard()  masks scales::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ dials::prune()    masks rpart::prune()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(probably) #install.packages('probably')\n\n\nAttaching package: 'probably'\n\n\nThe following objects are masked from 'package:base':\n\n    as.factor, as.ordered\n\ntidymodels_prefer()\nesgdata &lt;- read_csv('ESGData.csv')\n\nNew names:\n• `` -&gt; `...67`\n\n\nRows: 16013 Columns: 67\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Country Name, Country Code, Indicator Name, Indicator Code\ndbl (62): 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, ...\nlgl  (1): ...67\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nesgdata %&gt;% distinct(`Indicator Name`,`Indicator Code`)\n\n# A tibble: 67 × 2\n   `Indicator Name`                                             `Indicator Code`\n   &lt;chr&gt;                                                        &lt;chr&gt;           \n 1 Access to clean fuels and technologies for cooking (% of po… EG.CFT.ACCS.ZS  \n 2 Access to electricity (% of population)                      EG.ELC.ACCS.ZS  \n 3 Adjusted savings: natural resources depletion (% of GNI)     NY.ADJ.DRES.GN.…\n 4 Adjusted savings: net forest depletion (% of GNI)            NY.ADJ.DFOR.GN.…\n 5 Agricultural land (% of land area)                           AG.LND.AGRI.ZS  \n 6 Agriculture, forestry, and fishing, value added (% of GDP)   NV.AGR.TOTL.ZS  \n 7 Annual freshwater withdrawals, total (% of internal resourc… ER.H2O.FWTL.ZS  \n 8 Annualized average growth rate in per capita real survey me… SI.SPR.PCAP.ZG  \n 9 Cause of death, by communicable diseases and maternal, pren… SH.DTH.COMM.ZS  \n10 Children in employment, total (% of children ages 7-14)      SL.TLF.0714.ZS  \n# ℹ 57 more rows"
  },
  {
    "objectID": "Rmd/Final_Code_Appendix_Ayaa_Julia_Ting.html#data-cleaning",
    "href": "Rmd/Final_Code_Appendix_Ayaa_Julia_Ting.html#data-cleaning",
    "title": "Ayaa Asoba, Julia Coelho, Ting Huang stat253_project",
    "section": "Data cleaning",
    "text": "Data cleaning\n\n# data cleaning\nesgdata_clean &lt;- filter(esgdata,`Indicator Code`%in% c(\"EN.ATM.CO2E.PC\",\"EG.FEC.RNEW.ZS\", \"EG.ELC.RNEW.ZS\",\"EG.EGY.PRIM.PP.KD\",\"EG.USE.COMM.FO.ZS\",\"EN.POP.DNST\",\"AG.LND.AGRI.ZS\",\"NV.AGR.TOTL.ZS\",\"EG.ELC.ACCS.ZS\",\"SP.DYN.LE00.IN\",\"SI.DST.FRST.20\",\"SI.POV.GINI\",\"IT.NET.USER.ZS\",\"GE.EST\",\"AG.LND.FRST.ZS\",\"GB.XPD.RSDV.GD.ZS\",\"SE.PRM.ENRR\"))\nesgdata_clean &lt;- select(esgdata_clean,'Country Code','Country Name','Indicator Name','Indicator Code','1991','1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017','2018')\nesgdataAll &lt;- esgdata_clean %&gt;%\n  rename(CountryCode=\"Country Code\") %&gt;% rename(CountryName=\"Country Name\") %&gt;% rename(IndicatorName=\"Indicator Name\") %&gt;% rename(IndicatorCode=\"Indicator Code\")\nesgdataAll &lt;- esgdataAll %&gt;%\n  filter(!CountryCode %in% c(\"ARB\",\"CEB\",\"CSS\",\"ECA\",\"EAP\",\"EAR\",\"EAS\",\"ECS\",\"EMU\",\"EUU\",\"FCS\",\"HIC\",\"HPC\",\"IBD\",\"IBT\",\"IDA\",\"IDB\",\"IDX\",\"LDC\",\"LCN\",\"LIC\",\"LAC\",\"LMC\",\"LMY\",\"LTE\",\"MIC\",\"MEA\",\"MNA\",\"NAC\",\"OED\",\"OSS\",\"PRE\",\"PSS\",\"PST\",\"SAS\",\"SSA\",\"SSF\",\"SST\",\"TEA\",\"TMN\",\"TEC\",\"TLA\",\"TSA\",\"TSS\",\"UMC\",\"WLD\")) %&gt;%\n  pivot_longer(-c('CountryCode','CountryName','IndicatorName','IndicatorCode'), names_to = 'Year', values_to = 'Values') %&gt;% \n  select(-`IndicatorName`) %&gt;% \n  pivot_wider(names_from='IndicatorCode',values_from = 'Values')\nesgdataAll &lt;- esgdataAll %&gt;%\n   rename(electricity=\"EG.ELC.ACCS.ZS\") %&gt;% rename(agroLand=\"AG.LND.AGRI.ZS\") %&gt;% rename(agroValue=\"NV.AGR.TOTL.ZS\") %&gt;% rename(co2=\"EN.ATM.CO2E.PC\") %&gt;% rename(energyIntensity=\"EG.EGY.PRIM.PP.KD\") %&gt;% rename(forestArea=\"AG.LND.FRST.ZS\") %&gt;% rename(fossilFuel=\"EG.USE.COMM.FO.ZS\") %&gt;% rename(gini=\"SI.POV.GINI\") %&gt;% rename(govtEfficacy=\"GE.EST\") %&gt;% rename(incomeLowest20=\"SI.DST.FRST.20\") %&gt;% rename(internet=\"IT.NET.USER.ZS\") %&gt;% rename(lifeExpectancy=\"SP.DYN.LE00.IN\")  %&gt;% rename(popDensity=\"EN.POP.DNST\") %&gt;% rename(renewableElec=\"EG.ELC.RNEW.ZS\") %&gt;% rename(renewableEnergy=\"EG.FEC.RNEW.ZS\") %&gt;% rename(research=\"GB.XPD.RSDV.GD.ZS\") %&gt;% rename(schoolEnroll=\"SE.PRM.ENRR\")\nesgdataAll &lt;- esgdataAll %&gt;%\n  mutate(Year = as.numeric(Year))\nesgdataAll_sub &lt;- esgdataAll %&gt;% na.omit()\nesgdataAll_sub %&gt;% purrr::map (~sum(is.na(.)))\n\n$CountryCode\n[1] 0\n\n$CountryName\n[1] 0\n\n$Year\n[1] 0\n\n$electricity\n[1] 0\n\n$agroLand\n[1] 0\n\n$agroValue\n[1] 0\n\n$co2\n[1] 0\n\n$energyIntensity\n[1] 0\n\n$forestArea\n[1] 0\n\n$fossilFuel\n[1] 0\n\n$gini\n[1] 0\n\n$govtEfficacy\n[1] 0\n\n$incomeLowest20\n[1] 0\n\n$internet\n[1] 0\n\n$lifeExpectancy\n[1] 0\n\n$popDensity\n[1] 0\n\n$renewableElec\n[1] 0\n\n$renewableEnergy\n[1] 0\n\n$research\n[1] 0\n\n$schoolEnroll\n[1] 0\n\nesgdata_cv10 &lt;- vfold_cv(esgdataAll_sub, v = 10)  # 6 folds\ndata_rec &lt;- recipe(co2 ~ . , data = esgdataAll_sub) %&gt;%\n  update_role(`CountryCode`,new_role = 'ID') %&gt;%\n  update_role(`CountryName`,new_role = 'ID') %&gt;%\n    step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n    step_normalize(all_numeric_predictors()) %&gt;%  # important standardization step for LASSO\n    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables\ndata_rec %&gt;% prep(esgdataAll_sub) %&gt;%juice()\n\n# A tibble: 713 × 20\n   CountryCode CountryName    Year electricity agroLand agroValue\n   &lt;fct&gt;       &lt;fct&gt;         &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 ALB         Albania     -0.0415     0.291    -0.0194    1.94  \n 2 ARG         Argentina   -2.77      -0.304     0.170     0.0142\n 3 ARG         Argentina   -2.32      -0.238     0.173    -0.0472\n 4 ARG         Argentina   -1.86      -0.174     0.176    -0.145 \n 5 ARG         Argentina   -1.41      -0.112     0.180     0.802 \n 6 ARG         Argentina   -1.18      -0.0831    0.220     0.823 \n 7 ARG         Argentina   -0.952     -0.0548    0.285     0.486 \n 8 ARG         Argentina   -0.724     -0.0278    0.349     0.413 \n 9 ARG         Argentina   -0.497     -0.00166   0.410     0.241 \n10 ARG         Argentina   -0.269      0.0241    0.464     0.330 \n# ℹ 703 more rows\n# ℹ 14 more variables: energyIntensity &lt;dbl&gt;, forestArea &lt;dbl&gt;,\n#   fossilFuel &lt;dbl&gt;, gini &lt;dbl&gt;, govtEfficacy &lt;dbl&gt;, incomeLowest20 &lt;dbl&gt;,\n#   internet &lt;dbl&gt;, lifeExpectancy &lt;dbl&gt;, popDensity &lt;dbl&gt;,\n#   renewableElec &lt;dbl&gt;, renewableEnergy &lt;dbl&gt;, research &lt;dbl&gt;,\n#   schoolEnroll &lt;dbl&gt;, co2 &lt;dbl&gt;"
  },
  {
    "objectID": "Rmd/Final_Code_Appendix_Ayaa_Julia_Ting.html#regression-models",
    "href": "Rmd/Final_Code_Appendix_Ayaa_Julia_Ting.html#regression-models",
    "title": "Ayaa Asoba, Julia Coelho, Ting Huang stat253_project",
    "section": "Regression Models",
    "text": "Regression Models\n\nLinear Model Recipe\n\nesg_rec &lt;- recipe(co2 ~ . , data = esgdataAll_sub) %&gt;%\n  update_role(`Year`,new_role = 'ID') %&gt;%\n  update_role(`CountryCode`,new_role = 'ID') %&gt;%\n  update_role(`CountryName`,new_role = 'ID') %&gt;%\n    step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n    step_normalize(all_numeric_predictors()) %&gt;%  # important standardization step for LASSO\n    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables\n    \nesg_rec %&gt;% prep(esgdataAll_sub) %&gt;% juice()\n\n# A tibble: 713 × 20\n   CountryCode CountryName  Year electricity agroLand agroValue energyIntensity\n   &lt;fct&gt;       &lt;fct&gt;       &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;           &lt;dbl&gt;\n 1 ALB         Albania      2008     0.291    -0.0194    1.94            -0.640\n 2 ARG         Argentina    1996    -0.304     0.170     0.0142          -0.324\n 3 ARG         Argentina    1998    -0.238     0.173    -0.0472          -0.388\n 4 ARG         Argentina    2000    -0.174     0.176    -0.145           -0.298\n 5 ARG         Argentina    2002    -0.112     0.180     0.802           -0.186\n 6 ARG         Argentina    2003    -0.0831    0.220     0.823           -0.210\n 7 ARG         Argentina    2004    -0.0548    0.285     0.486           -0.207\n 8 ARG         Argentina    2005    -0.0278    0.349     0.413           -0.314\n 9 ARG         Argentina    2006    -0.00166   0.410     0.241           -0.306\n10 ARG         Argentina    2007     0.0241    0.464     0.330           -0.398\n# ℹ 703 more rows\n# ℹ 13 more variables: forestArea &lt;dbl&gt;, fossilFuel &lt;dbl&gt;, gini &lt;dbl&gt;,\n#   govtEfficacy &lt;dbl&gt;, incomeLowest20 &lt;dbl&gt;, internet &lt;dbl&gt;,\n#   lifeExpectancy &lt;dbl&gt;, popDensity &lt;dbl&gt;, renewableElec &lt;dbl&gt;,\n#   renewableEnergy &lt;dbl&gt;, research &lt;dbl&gt;, schoolEnroll &lt;dbl&gt;, co2 &lt;dbl&gt;\n\n\n\n\nLinear Model Fit\n\nlm_spec &lt;- \n    linear_reg() %&gt;% \n    set_engine(engine = 'lm') %&gt;% \n    set_mode('regression')\nesg_model_wf1 &lt;- workflow() %&gt;%\n  add_recipe(esg_rec) %&gt;% \n  add_model(lm_spec)\n \nesg_fit_model1 &lt;- esg_model_wf1 %&gt;% \n  fit(data = esgdataAll_sub)\nesg_fit_model1 %&gt;% tidy() \n\n# A tibble: 17 × 5\n   term            estimate std.error statistic   p.value\n   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)       6.55       0.105    62.3   4.59e-287\n 2 electricity       0.0221     0.170     0.130 8.97e-  1\n 3 agroLand         -0.143      0.146    -0.975 3.30e-  1\n 4 agroValue        -0.842      0.200    -4.21  2.86e-  5\n 5 energyIntensity   1.14       0.148     7.72  4.09e- 14\n 6 forestArea        0.264      0.161     1.64  1.00e-  1\n 7 fossilFuel        0.775      0.212     3.65  2.77e-  4\n 8 gini             -0.497      0.460    -1.08  2.81e-  1\n 9 govtEfficacy      2.18       0.251     8.69  2.52e- 17\n10 incomeLowest20   -0.408      0.433    -0.944 3.46e-  1\n11 internet          0.425      0.204     2.08  3.75e-  2\n12 lifeExpectancy   -0.835      0.240    -3.49  5.21e-  4\n13 popDensity       -0.492      0.123    -3.99  7.46e-  5\n14 renewableElec    -0.119      0.220    -0.541 5.89e-  1\n15 renewableEnergy  -1.20       0.306    -3.93  9.53e-  5\n16 research          0.477      0.187     2.55  1.10e-  2\n17 schoolEnroll     -0.185      0.134    -1.39  1.66e-  1\n\n\n\n# Getting metrics\ncv_output &lt;- fit_resamples( # new function for tuning parameters\n  esg_model_wf1, # workflow\n  resamples = esgdata_cv10, # cv folds\n  metrics = metric_set(rmse, mae, rsq)\n)\ncv_output %&gt;% collect_metrics()\n\n# A tibble: 3 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   2.01     10  0.0709 Preprocessor1_Model1\n2 rmse    standard   2.84     10  0.106  Preprocessor1_Model1\n3 rsq     standard   0.604    10  0.0173 Preprocessor1_Model1\n\n# Residuals \nesg_fit_model1_residuals &lt;- bind_cols(esgdataAll_sub, esg_fit_model1 %&gt;% \n  predict(new_data = esgdataAll_sub)) %&gt;%\n  mutate(resid = co2 - .pred)\nggplot(esg_fit_model1_residuals, aes(x = .pred, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    ggtitle(\"Linear Regression Residuals\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()    # fit to the training data \n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nLASSO Model\n\ndata_rec &lt;- recipe(co2 ~ . , data = esgdataAll_sub) %&gt;%\n  update_role(`Year`,new_role = 'ID') %&gt;%\n  update_role(`CountryCode`,new_role = 'ID') %&gt;%\n  update_role(`CountryName`,new_role = 'ID') %&gt;%\n    step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n    step_normalize(all_numeric_predictors()) %&gt;%  # important standardization step for LASSO\n    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables\n# Lasso Model Spec with tune\nlm_lasso_spec_tune &lt;- \n  linear_reg() %&gt;%\n  set_args(mixture = 1, penalty = tune()) %&gt;% ## mixture = 1 indicates Lasso\n  set_engine(engine = 'glmnet') %&gt;% #note we are using a different engine\n  set_mode('regression') \n# Workflow (Recipe + Model)\nlasso_wf_tune &lt;- workflow() %&gt;% \n  add_recipe(data_rec) %&gt;%\n  add_model(lm_lasso_spec_tune) \n# Tune Model (trying a variety of values of Lambda penalty)\npenalty_grid &lt;- grid_regular(\n  penalty(range = c(-3, 1)), #log10 transformed \n  levels = 30)\ntune_output &lt;- tune_grid( # new function for tuning hyperparameters\n  lasso_wf_tune, # workflow\n  resamples = esgdata_cv10, # cv folds\n  metrics = metric_set(rmse, mae),\n  grid = penalty_grid # penalty grid defined above\n)\nautoplot(tune_output) + theme_classic()\n\n\n\n\n\n\n\n\n\nPicking LASSO Penalty\n\nbest_penalty &lt;- select_best(tune_output, metric = 'mae') # choose penalty value based on lowest mae\nbest_penalty\n\n# A tibble: 1 × 2\n  penalty .config              \n    &lt;dbl&gt; &lt;chr&gt;                \n1  0.0853 Preprocessor1_Model15\n\nbest_se_penalty &lt;- select_by_one_std_err(tune_output, metric = 'mae', desc(penalty)) # choose penalty value based on the largest penalty within 1 se of the lowest CV MAE\nbest_se_penalty\n\n# A tibble: 1 × 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt;  &lt;dbl&gt;\n1   0.304 mae     standard    2.03    10  0.0713 Preprocessor1_Mod…  1.97   2.05\n\nfinal_wf &lt;- finalize_workflow(lasso_wf_tune, best_penalty) # incorporates penalty value to workflow\nfinal_wf_se &lt;- finalize_workflow(lasso_wf_tune, best_se_penalty) # incorporates penalty value to workflow\nfinal_fit &lt;- fit(final_wf, data = esgdataAll_sub)\nfinal_fit_se &lt;- fit(final_wf_se, data = esgdataAll_sub)\ntidy(final_fit)\n\n# A tibble: 17 × 3\n   term            estimate penalty\n   &lt;chr&gt;              &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)       6.55    0.0853\n 2 electricity       0       0.0853\n 3 agroLand         -0.0480  0.0853\n 4 agroValue        -0.851   0.0853\n 5 energyIntensity   1.09    0.0853\n 6 forestArea        0.141   0.0853\n 7 fossilFuel        0.514   0.0853\n 8 gini             -0.0230  0.0853\n 9 govtEfficacy      1.80    0.0853\n10 incomeLowest20    0       0.0853\n11 internet          0.225   0.0853\n12 lifeExpectancy   -0.280   0.0853\n13 popDensity       -0.414   0.0853\n14 renewableElec    -0.232   0.0853\n15 renewableEnergy  -1.12    0.0853\n16 research          0.519   0.0853\n17 schoolEnroll     -0.224   0.0853\n\ntidy(final_fit_se)\n\n# A tibble: 17 × 3\n   term             estimate penalty\n   &lt;chr&gt;               &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)      6.55       0.304\n 2 electricity      0          0.304\n 3 agroLand         0          0.304\n 4 agroValue       -0.751      0.304\n 5 energyIntensity  0.760      0.304\n 6 forestArea       0          0.304\n 7 fossilFuel       0.000135   0.304\n 8 gini             0          0.304\n 9 govtEfficacy     1.36       0.304\n10 incomeLowest20   0          0.304\n11 internet         0          0.304\n12 lifeExpectancy   0          0.304\n13 popDensity      -0.115      0.304\n14 renewableElec   -0.241      0.304\n15 renewableEnergy -1.18       0.304\n16 research         0.598      0.304\n17 schoolEnroll    -0.167      0.304\n\n\n\nglmnet_output &lt;- final_fit_se %&gt;% extract_fit_parsnip() %&gt;% pluck('fit') # way to get the original glmnet output\nlambdas &lt;- glmnet_output$lambda\ncoefs_lambdas &lt;- \n  coefficients(glmnet_output, s = lambdas )  %&gt;% \n  as.matrix() %&gt;%  \n  t() %&gt;% \n  as.data.frame() %&gt;% \n  mutate(lambda = lambdas ) %&gt;% \n  select(lambda, everything(), -`(Intercept)`) %&gt;% \n  pivot_longer(cols = -lambda, \n               names_to = \"term\", \n               values_to = \"coef\") %&gt;%\n  mutate(var = map_chr(stringr::str_split(term,\"_\"),~.[1]))\ncoefs_lambdas %&gt;%\n  ggplot(aes(x = lambda, y = coef, group = term, color = var)) +\n  geom_line() +\n  geom_vline(xintercept = best_se_penalty %&gt;% pull(penalty), linetype = 'dashed') + \n  theme_classic() + \n  theme(legend.position = \"bottom\", legend.text=element_text(size=8))\n\n\n\n\n\n\n\n# Create a boolean matrix (predictors x lambdas) of variable exclusion\nbool_predictor_exclude &lt;- glmnet_output$beta==0\n# Loop over each variable\nvar_imp &lt;- sapply(seq_len(nrow(bool_predictor_exclude)), function(row) {\n    this_coeff_path &lt;- bool_predictor_exclude[row,]\n    if(sum(this_coeff_path) == ncol(bool_predictor_exclude)){ return(0)}else{\n    return(ncol(bool_predictor_exclude) - which.min(this_coeff_path) + 1)}\n})\n# Create a dataset of this information and sort\nvar_imp_data &lt;- tibble(\n    var_name = rownames(bool_predictor_exclude),\n    var_imp = var_imp\n)\nvar_imp_data %&gt;% arrange(desc(var_imp))\n\n# A tibble: 16 × 2\n   var_name        var_imp\n   &lt;chr&gt;             &lt;dbl&gt;\n 1 govtEfficacy         75\n 2 agroValue            74\n 3 renewableElec        73\n 4 renewableEnergy      73\n 5 research             73\n 6 energyIntensity      63\n 7 gini                 63\n 8 schoolEnroll         60\n 9 popDensity           55\n10 fossilFuel           53\n11 internet             52\n12 forestArea           46\n13 agroLand             44\n14 lifeExpectancy       44\n15 incomeLowest20       18\n16 electricity          10\n\n\n\nfinal_fit_se %&gt;% tidy() %&gt;% filter(estimate != 0)\n\n# A tibble: 10 × 3\n   term             estimate penalty\n   &lt;chr&gt;               &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)      6.55       0.304\n 2 agroValue       -0.751      0.304\n 3 energyIntensity  0.760      0.304\n 4 fossilFuel       0.000135   0.304\n 5 govtEfficacy     1.36       0.304\n 6 popDensity      -0.115      0.304\n 7 renewableElec   -0.241      0.304\n 8 renewableEnergy -1.18       0.304\n 9 research         0.598      0.304\n10 schoolEnroll    -0.167      0.304\n\ntune_output %&gt;% collect_metrics() %&gt;% filter(penalty == (best_se_penalty %&gt;% pull(penalty)))\n\n# A tibble: 2 × 7\n  penalty .metric .estimator  mean     n std_err .config              \n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1   0.304 mae     standard    2.03    10  0.0713 Preprocessor1_Model19\n2   0.304 rmse    standard    2.95    10  0.111  Preprocessor1_Model19\n\nlasso_mod_out &lt;- final_fit_se %&gt;%\n    predict(new_data = esgdataAll_sub) %&gt;%\n    bind_cols(esgdataAll_sub) %&gt;%\n    mutate(resid = co2 - .pred)\nggplot(esg_fit_model1_residuals, aes(x = .pred, y = resid)) +\n    geom_point() +\n    ggtitle('Linear Regression Final Model') +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()    # fit to the training data \n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\nlasso_mod_out %&gt;% \n  ggplot(aes(x = .pred, y = resid)) + \n  ggtitle('LASSO Residuals') +\n  geom_point() +\n  geom_smooth(se = FALSE) + \n  geom_hline(yintercept = 0, color = \"red\") + \n  theme_classic()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nGAMs\n\ngam_spec &lt;- \n  gen_additive_mod() %&gt;%\n  set_engine(engine = 'mgcv') %&gt;%\n  set_mode('regression') \ngam_mod &lt;- fit(gam_spec,\n    co2 ~ s(agroValue) + s(energyIntensity) + s(fossilFuel) + s(govtEfficacy) + s(popDensity) + s(renewableElec) + s(research) + s(schoolEnroll),\n    data = esgdataAll_sub\n)\n\n\ngam_mod %&gt;% pluck('fit') %&gt;% plot( all.terms = TRUE, pages = 1)\n\n\n\n\n\n\n\ngam_mod %&gt;% pluck('fit') %&gt;% summary() \n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nco2 ~ s(agroValue) + s(energyIntensity) + s(fossilFuel) + s(govtEfficacy) + \n    s(popDensity) + s(renewableElec) + s(research) + s(schoolEnroll)\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.55010    0.06926   94.58   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                     edf Ref.df      F  p-value    \ns(agroValue)       8.600  8.948 13.878  &lt; 2e-16 ***\ns(energyIntensity) 8.801  8.985 27.180  &lt; 2e-16 ***\ns(fossilFuel)      8.468  8.909 11.883  &lt; 2e-16 ***\ns(govtEfficacy)    7.026  8.134  9.503  &lt; 2e-16 ***\ns(popDensity)      8.957  8.999 13.224  &lt; 2e-16 ***\ns(renewableElec)   7.970  8.705  5.465 1.28e-06 ***\ns(research)        8.182  8.817  9.380  &lt; 2e-16 ***\ns(schoolEnroll)    7.599  8.511  5.386 1.24e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.831   Deviance explained = 84.6%\nGCV = 3.7724  Scale est. = 3.42      n = 713\n\n\n\ngam_data_rec &lt;- recipe(co2 ~ agroValue + energyIntensity + fossilFuel + govtEfficacy + popDensity + renewableElec + research + schoolEnroll , data = esgdataAll_sub) %&gt;%\n    step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n    step_dummy(all_nominal_predictors()) %&gt;%  # creates indicator variables for categorical variables\n     step_ns(agroValue, deg_free = 9) %&gt;% \n     step_ns(energyIntensity, deg_free = 9) %&gt;%\n     step_ns(fossilFuel, deg_free = 8) %&gt;%\n     step_ns(govtEfficacy, deg_free = 7) %&gt;%\n     step_ns(popDensity, deg_free = 9) %&gt;%\n     step_ns(renewableElec, deg_free = 8) %&gt;%\n     step_ns(research, deg_free = 8) %&gt;% \n    step_ns(schoolEnroll, deg_free = 8)\nspline_wf &lt;- workflow() %&gt;%\n    add_model(lm_spec) %&gt;%\n    add_recipe(gam_data_rec)\nfit_resamples(\n    spline_wf ,\n    resamples = esgdata_cv10, # cv folds\n    metrics = metric_set(mae,rsq)                     \n) %&gt;% collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   1.36     10  0.0353 Preprocessor1_Model1\n2 rsq     standard   0.833    10  0.0119 Preprocessor1_Model1\n\nesg_gam_model2 &lt;- spline_wf %&gt;% fit(data=esgdataAll_sub)\nesg_gam_model2_residuals &lt;- bind_cols(esgdataAll_sub, esg_gam_model2 %&gt;% \n  predict(new_data = esgdataAll_sub)) %&gt;%\n  mutate(resid = co2 - .pred)\nresid_agro &lt;- ggplot(esg_gam_model2_residuals, aes(x = agroValue, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()   \nresid_energy &lt;- ggplot(esg_gam_model2_residuals, aes(x = energyIntensity, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic() \nresid_fossil &lt;- ggplot(esg_gam_model2_residuals, aes(x = fossilFuel, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()\nresid_govt &lt;- ggplot(esg_gam_model2_residuals, aes(x = govtEfficacy, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()\nresid_density &lt;- ggplot(esg_gam_model2_residuals, aes(x = popDensity, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()\nresid_renewable &lt;- ggplot(esg_gam_model2_residuals, aes(x = renewableElec, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()\nresid_research &lt;- ggplot(esg_gam_model2_residuals, aes(x = research, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()\nresid_school &lt;- ggplot(esg_gam_model2_residuals, aes(x = agroValue , y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    labs(x = \"Fitted values\", y = \"Residuals\") +\n    theme_classic()\nggplot(esg_gam_model2_residuals, aes(x = resid, y = co2)) +\n    geom_point(alpha = 0.25) +\n    geom_smooth(color = \"blue\", se = FALSE) +\n    theme_classic()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggarrange(resid_agro, resid_energy, resid_fossil, resid_govt, resid_density, resid_renewable, resid_research, resid_school + rremove(\"x.text\"), \n          labels = c(\"agroValue Residuals\", \"energyIntensity Residuals\", \"fossilFuel Residuals\", \"govtEfficacy Residuals\", \"popDensity Residuals\", \"renewableElec Residuals\", \"research Residuals\", \"schoolEnroll Residuals\"),\n          ncol = 4, nrow = 2)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "Rmd/Final_Code_Appendix_Ayaa_Julia_Ting.html#classification-models",
    "href": "Rmd/Final_Code_Appendix_Ayaa_Julia_Ting.html#classification-models",
    "title": "Ayaa Asoba, Julia Coelho, Ting Huang stat253_project",
    "section": "Classification Models",
    "text": "Classification Models\n\nmean(esgdataAll_sub[[\"co2\"]])\n\n[1] 6.550097\n\nesgdataAll_sub &lt;- esgdataAll_sub %&gt;%\n  mutate(CO2cat = if_else(esgdataAll_sub$co2 &gt; 6.550097, 'high_co2','low_co2'))\nesgdataAll_sub &lt;- esgdataAll_sub %&gt;%\n  mutate(CO2cat = relevel(factor(CO2cat), ref= 'low_co2'))\n\n\nWe will be using 6.550097 as the split for deciding if the country has high CO2 emissions or low CO2 emissions. ### Logistic Regression\n\n\n# Logistic Regression Model Spec\n\nlogistic_spec &lt;- logistic_reg() %&gt;%\n    set_engine('glm') %&gt;%\n    set_mode('classification')\n    \n# Recipe\n logistic_rec &lt;- recipe( CO2cat ~ ., data = esgdataAll_sub) %&gt;%\n    update_role(`CountryCode`,new_role = 'ID') %&gt;%\n     update_role(`CountryName`,new_role = 'ID') %&gt;%\n     step_rm(co2) %&gt;%\n     step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n     step_normalize(all_numeric_predictors()) %&gt;%  # important standardization step for LASSO\n     step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables\n# Workflow (Recipe + Model)\n\nlog_wf &lt;- workflow() %&gt;% \n    add_recipe(logistic_rec) %&gt;%\n    add_model(logistic_spec) \n# Fit Model to Training Data\nlog_fit &lt;- fit(log_wf, data = esgdataAll_sub)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\nExamining the logistic model\n\n# Print out Coefficients\nlog_fit %&gt;% tidy()\n\n# A tibble: 18 × 5\n   term            estimate std.error statistic  p.value\n   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)       -2.16      0.351    -6.16  7.38e-10\n 2 Year              -0.770     0.276    -2.79  5.32e- 3\n 3 electricity        0.517     1.09      0.476 6.34e- 1\n 4 agroLand          -0.654     0.260    -2.51  1.21e- 2\n 5 agroValue         -3.62      0.566    -6.38  1.72e-10\n 6 energyIntensity    1.77      0.287     6.17  6.68e-10\n 7 forestArea        -0.234     0.239    -0.979 3.27e- 1\n 8 fossilFuel         2.04      0.288     7.09  1.30e-12\n 9 gini              -0.431     0.744    -0.580 5.62e- 1\n10 govtEfficacy       0.954     0.416     2.29  2.19e- 2\n11 incomeLowest20    -0.484     0.640    -0.757 4.49e- 1\n12 internet           1.23      0.437     2.82  4.84e- 3\n13 lifeExpectancy    -0.357     0.286    -1.25  2.12e- 1\n14 popDensity        -0.794     0.164    -4.85  1.25e- 6\n15 renewableElec     -0.624     0.404    -1.54  1.23e- 1\n16 renewableEnergy   -0.392     0.511    -0.767 4.43e- 1\n17 research           0.531     0.267     1.99  4.70e- 2\n18 schoolEnroll      -0.616     0.223    -2.75  5.88e- 3\n\n# Get Exponentiated coefficients + CI\nlog_fit %&gt;% tidy() %&gt;%\n  mutate(OR.conf.low = exp(estimate - 1.96*std.error), OR.conf.high = exp(estimate + 1.96*std.error)) %&gt;% # do this first\n  mutate(OR = exp(estimate))\n\n# A tibble: 18 × 8\n   term    estimate std.error statistic  p.value OR.conf.low OR.conf.high     OR\n   &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n 1 (Inter…   -2.16      0.351    -6.16  7.38e-10     0.0578        0.229  0.115 \n 2 Year      -0.770     0.276    -2.79  5.32e- 3     0.269         0.796  0.463 \n 3 electr…    0.517     1.09      0.476 6.34e- 1     0.200        14.1    1.68  \n 4 agroLa…   -0.654     0.260    -2.51  1.21e- 2     0.312         0.866  0.520 \n 5 agroVa…   -3.62      0.566    -6.38  1.72e-10     0.00886       0.0816 0.0269\n 6 energy…    1.77      0.287     6.17  6.68e-10     3.36         10.4    5.90  \n 7 forest…   -0.234     0.239    -0.979 3.27e- 1     0.495         1.26   0.791 \n 8 fossil…    2.04      0.288     7.09  1.30e-12     4.39         13.6    7.71  \n 9 gini      -0.431     0.744    -0.580 5.62e- 1     0.151         2.79   0.650 \n10 govtEf…    0.954     0.416     2.29  2.19e- 2     1.15          5.87   2.60  \n11 income…   -0.484     0.640    -0.757 4.49e- 1     0.176         2.16   0.616 \n12 intern…    1.23      0.437     2.82  4.84e- 3     1.45          8.05   3.42  \n13 lifeEx…   -0.357     0.286    -1.25  2.12e- 1     0.400         1.23   0.700 \n14 popDen…   -0.794     0.164    -4.85  1.25e- 6     0.328         0.623  0.452 \n15 renewa…   -0.624     0.404    -1.54  1.23e- 1     0.243         1.18   0.536 \n16 renewa…   -0.392     0.511    -0.767 4.43e- 1     0.248         1.84   0.676 \n17 resear…    0.531     0.267     1.99  4.70e- 2     1.01          2.87   1.70  \n18 school…   -0.616     0.223    -2.75  5.88e- 3     0.349         0.837  0.540 \n\n\n\nlogistic_output &lt;-  esgdataAll_sub %&gt;%\n  bind_cols(predict(log_fit, new_data = esgdataAll_sub, type = 'prob')) \n# Hard predictions (you pick threshold)\nlogistic_output &lt;- logistic_output %&gt;%\n  mutate(.pred_class = make_two_class_pred(.pred_low_co2, levels(CO2cat), threshold = .55)) #Try changing threshold (.5, 0, 1, .2, .8)\n# Visualize Soft Predictions\nlogistic_output %&gt;%\n  ggplot(aes(x = CO2cat, y = .pred_low_co2)) +\n  geom_boxplot() + \n  geom_hline(yintercept = 0.55, color='red') +  # try changing threshold\n  labs(y = 'Predicted Probability of Low CO2', x = 'Observed Outcome') +\n  theme_classic()\n\n\n\n\n\n\n\nlogistic_output %&gt;%\n  conf_mat(truth = CO2cat, estimate = .pred_class)\n\n          Truth\nPrediction low_co2 high_co2\n  low_co2      357       39\n  high_co2      45      272\n\nlog_metrics &lt;- metric_set(sens, yardstick::spec, accuracy) # these metrics are based on hard predictions\n#sens: sensitivity = chance of correctly predicting second level, given second level (Yes)\n#spec: specificity = chance of correctly predicting first level, given first level (No)\n#accuracy: accuracy = chance of correctly predicting outcome\nlogistic_output %&gt;% \n   log_metrics(estimate = .pred_class, truth = CO2cat, event_level = \"second\") # set second level of outcome as \"success\"\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 sens     binary         0.875\n2 spec     binary         0.888\n3 accuracy binary         0.882\n\n\n\n logistic_output &lt;-  esgdataAll_sub %&gt;%\n   bind_cols(predict(log_fit, new_data = esgdataAll_sub, type = 'prob')) \n logistic_roc &lt;- logistic_output %&gt;% \n     roc_curve(CO2cat, .pred_high_co2, event_level = \"second\") # set second level of outcome as \"success\"\n autoplot(logistic_roc) + theme_classic()\n\n\n\n\n\n\n\n set.seed(123)\n esgdataAll_sub_cv10 &lt;- vfold_cv(esgdataAll_sub, v = 10)\n # CV Fit Model\n log_cv_fit &lt;- fit_resamples(\n     log_wf, \n     resamples = esgdataAll_sub_cv10,\n     metrics = metric_set(sens, yardstick::spec, accuracy, roc_auc),\n     control = control_resamples(save_pred = TRUE, event_level = 'second'))  # you need predictions for ROC calculations\n\n→ A | warning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x10\n\n\n\n\n collect_metrics(log_cv_fit) #default threshold is 0.5\n\n# A tibble: 4 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.864    10 0.0128  Preprocessor1_Model1\n2 roc_auc  binary     0.943    10 0.00729 Preprocessor1_Model1\n3 sens     binary     0.843    10 0.0250  Preprocessor1_Model1\n4 spec     binary     0.882    10 0.0139  Preprocessor1_Model1\n\n\n\nDecision tree\n\nset.seed(726) # don't change this\nct_spec_tune &lt;- decision_tree() %&gt;%\n  set_engine(engine = 'rpart') %&gt;%\n  set_args(cost_complexity = tune(),  \n           min_n = 2, \n           tree_depth = NULL) %&gt;% \n  set_mode('classification') \ndata_rec &lt;- recipe(CO2cat ~ ., data = esgdataAll_sub) %&gt;%\n    update_role(`CountryCode`,new_role = 'ID') %&gt;%\n    update_role(`CountryName`,new_role = 'ID') %&gt;%\n    step_rm(co2) %&gt;%\n    step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables\ndata_wf_tune &lt;- workflow() %&gt;%\n  add_model(ct_spec_tune) %&gt;%\n  add_recipe(data_rec)\nparam_grid &lt;- grid_regular(cost_complexity(range = c(-5, 1)), levels = 10) \ntune_res &lt;- tune_grid(\n  data_wf_tune, \n  resamples = esgdataAll_sub_cv10, \n  grid = param_grid, \n  metrics = metric_set(accuracy) #change this for regression trees\n)\n\n\nautoplot(tune_res) + theme_classic()\n\n\n\n\n\n\n\n\n\nbest_complexity &lt;- select_by_one_std_err(tune_res, metric = 'accuracy', desc(cost_complexity))\ndata_wf_final &lt;- finalize_workflow(data_wf_tune, best_complexity)\nesg_final_fit &lt;- fit(data_wf_final, data = esgdataAll_sub)\n\n\nesg_final_fit %&gt;% extract_fit_engine() %&gt;% rpart.plot()\n\nWarning: Cannot retrieve the data used to build the model (so cannot determine roundint and is.binary for the variables).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE.\n\n\n\n\n\n\n\n\n\n\ntree_mod_highcp &lt;- fit(\n    data_wf_tune %&gt;%\n        update_model(ct_spec_tune %&gt;% set_args(cost_complexity = .01)),\n    data = esgdataAll_sub\n)\ntree_mod_highcp %&gt;% extract_fit_engine() %&gt;% rpart.plot()\n\nWarning: Cannot retrieve the data used to build the model (so cannot determine roundint and is.binary for the variables).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE.\n\n\n\n\n\n\n\n\n\n\n\nRandom Forest\n\n# Model Specification\nrf_spec &lt;- rand_forest() %&gt;%\n  set_engine(engine = 'ranger') %&gt;% \n  set_args(mtry = NULL, # size of random subset of variables; default is floor(sqrt(number of total predictors))\n           trees = 1000, # Number of trees\n           min_n = 2,\n           probability = FALSE, # FALSE: get hard predictions (not needed for regression)\n           importance = 'impurity') %&gt;% # we'll come back to this at the end\n  set_mode('classification') # change this for regression\n# Recipe\ndata_rec_rf &lt;- recipe(CO2cat ~ ., data = esgdataAll_sub) %&gt;%\n  update_role(`CountryCode`,new_role = 'ID') %&gt;%\n    update_role(`CountryName`,new_role = 'ID') %&gt;%\n    step_rm(co2) %&gt;%\n    step_nzv(all_predictors()) %&gt;% # removes variables with the same value\n    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables\n# Workflows\ndata_wf_mtry2 &lt;- workflow() %&gt;%\n  add_model(rf_spec %&gt;% set_args(mtry = 2)) %&gt;%\n  add_recipe(data_rec_rf)\n## Create workflows for mtry = 4, 9, and 17\ndata_wf_mtry4 &lt;- workflow() %&gt;%\n  add_model(rf_spec %&gt;% set_args(mtry = 4)) %&gt;%\n  add_recipe(data_rec_rf)\ndata_wf_mtry9 &lt;- workflow() %&gt;%\n  add_model(rf_spec %&gt;% set_args(mtry = 9)) %&gt;%\n  add_recipe(data_rec_rf)\ndata_wf_mtry17 &lt;- workflow() %&gt;%\n  add_model(rf_spec %&gt;% set_args(mtry = 17)) %&gt;%\n  add_recipe(data_rec_rf)\n\n\nset.seed(726) # make sure to run this before each fit so that you have the same 1000 trees\ndata_fit_mtry2 &lt;- fit(data_wf_mtry2, data = esgdataAll_sub)\nset.seed(726)\ndata_fit_mtry4 &lt;- fit(data_wf_mtry4, data = esgdataAll_sub)\nset.seed(726) \ndata_fit_mtry9 &lt;- fit(data_wf_mtry9, data = esgdataAll_sub)\nset.seed(726)\ndata_fit_mtry17 &lt;- fit(data_wf_mtry17, data = esgdataAll_sub)\n\n\nrf_OOB_output &lt;- function(fit_model, model_label, truth){\n    tibble(\n          .pred_class = fit_model %&gt;% extract_fit_engine() %&gt;% pluck('predictions'), #OOB predictions\n          class = truth,\n          model = model_label\n      )\n}\n#check out the function output\nrf_OOB_output(data_fit_mtry2,'mtry2', esgdataAll_sub %&gt;% pull(CO2cat))\n\n# A tibble: 713 × 3\n   .pred_class class   model\n   &lt;fct&gt;       &lt;fct&gt;   &lt;chr&gt;\n 1 low_co2     low_co2 mtry2\n 2 low_co2     low_co2 mtry2\n 3 low_co2     low_co2 mtry2\n 4 low_co2     low_co2 mtry2\n 5 low_co2     low_co2 mtry2\n 6 low_co2     low_co2 mtry2\n 7 low_co2     low_co2 mtry2\n 8 low_co2     low_co2 mtry2\n 9 low_co2     low_co2 mtry2\n10 low_co2     low_co2 mtry2\n# ℹ 703 more rows\n\n\n\ndata_rf_OOB_output &lt;- bind_rows(\n    rf_OOB_output(data_fit_mtry2,'mtry2', esgdataAll_sub %&gt;% pull(CO2cat)),\n    rf_OOB_output(data_fit_mtry4,'mtry4', esgdataAll_sub %&gt;% pull(CO2cat)),\n    rf_OOB_output(data_fit_mtry9,'mtry9', esgdataAll_sub %&gt;% pull(CO2cat)),\n    rf_OOB_output(data_fit_mtry17,'mtry17', esgdataAll_sub %&gt;% pull(CO2cat))\n)\ndata_rf_OOB_output %&gt;% \n    group_by(model) %&gt;%\n    accuracy(truth = class, estimate = .pred_class)\n\n# A tibble: 4 × 4\n  model  .metric  .estimator .estimate\n  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 mtry17 accuracy binary         0.954\n2 mtry2  accuracy binary         0.959\n3 mtry4  accuracy binary         0.959\n4 mtry9  accuracy binary         0.962\n\n\n\ndata_rf_OOB_output %&gt;% \n    group_by(model) %&gt;%\n    accuracy(truth = class, estimate = .pred_class) %&gt;%\n  mutate(mtry = as.numeric(stringr::str_replace(model,'mtry',''))) %&gt;%\n  ggplot(aes(x = mtry, y = .estimate )) + \n  geom_point() +\n  geom_line() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nrf_OOB_output(data_fit_mtry9,'mtry9', esgdataAll_sub %&gt;% pull(CO2cat)) %&gt;%\n    conf_mat(truth = class, estimate= .pred_class)\n\n          Truth\nPrediction low_co2 high_co2\n  low_co2      389       14\n  high_co2      13      297\n\n\n\ndata_fit_mtry9 %&gt;% \n    extract_fit_engine() %&gt;% \n    vip(num_features = 30) + theme_classic() #based on impurity"
  },
  {
    "objectID": "Rmd/Final_Code_Appendix_Ayaa_Julia_Ting.html#clustering",
    "href": "Rmd/Final_Code_Appendix_Ayaa_Julia_Ting.html#clustering",
    "title": "Ayaa Asoba, Julia Coelho, Ting Huang stat253_project",
    "section": "Clustering",
    "text": "Clustering\n\nSUB = esgdataAll_sub %&gt;%\n  select(co2,govtEfficacy,agroValue,research,renewableEnergy)\nset.seed(123)\nkclust_k4 &lt;- kmeans(scale(SUB), centers = 4)\nesgdataAll_sub &lt;- esgdataAll_sub %&gt;%\n    mutate(kclust_4 = factor(kclust_k4$cluster))\nggplot(esgdataAll_sub,aes(co2,govtEfficacy,color=kclust_4)) +\n  geom_point()\n\n\n\n\n\n\n\nggplot(esgdataAll_sub,aes(co2,agroValue,color=kclust_4)) +\n  geom_point()\n\n\n\n\n\n\n\nggplot(esgdataAll_sub,aes(co2,renewableEnergy,color=kclust_4)) +\n  geom_point()\n\n\n\n\n\n\n\nggplot(esgdataAll_sub,aes(co2,research,color=kclust_4)) +\n  geom_point()\n\n\n\n\n\n\n\nesgdataAll_sub %&gt;%\n    group_by(kclust_4) %&gt;%\n    summarize(across(c(co2,govtEfficacy,agroValue,research,renewableEnergy), mean))\n\n# A tibble: 4 × 6\n  kclust_4   co2 govtEfficacy agroValue research renewableEnergy\n  &lt;fct&gt;    &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;\n1 1        10.5         1.71       1.64    2.46             22.4\n2 2         1.03       -0.689     20.3     0.193            51.3\n3 3         3.42       -0.107      7.82    0.441            20.6\n4 4         7.85        0.823      2.82    1.01             10.3\n\nesgdataAll_sub %&gt;%\n  count(kclust_4, CountryName)\n\n# A tibble: 102 × 3\n   kclust_4 CountryName        n\n   &lt;fct&gt;    &lt;chr&gt;          &lt;int&gt;\n 1 1        Australia          2\n 2 1        Austria           14\n 3 1        Belgium           14\n 4 1        Canada             9\n 5 1        Czech Republic     2\n 6 1        Denmark           12\n 7 1        Estonia            6\n 8 1        Finland           14\n 9 1        France            13\n10 1        Germany           16\n# ℹ 92 more rows\n\n\n\nesg_cluster_ss &lt;- function(k){\n    # Perform clustering\n    kclust &lt;- kmeans(scale(SUB), centers = k)\n    # Return the total within-cluster sum of squares\n    return(kclust$tot.withinss)\n}\ntibble(\n    k = 1:15,\n    tot_wc_ss = purrr::map_dbl(1:15, esg_cluster_ss)\n) %&gt;% \n    ggplot(aes(x = k, y = tot_wc_ss)) +\n    geom_point() + \n    labs(x = \"Number of clusters\",y = 'Total within-cluster sum of squares') + \n    theme_classic()"
  }
]